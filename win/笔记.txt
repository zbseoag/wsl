wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb
sudo dpkg -i percona-release_latest.generic_all.deb
sudo percona-release enable-only ps-80 release
sudo percona-release enable tools release
sudo apt-get update
sudo apt-get install percona-server-server percona-server-client percona-toolkit percona-xtrabackup-80 sysbenc

HTTP1.0 TCP不能复用
HTTP1.1 顺序性TCP复用
HTTP2.0 多路复用TCP复用

HTTP请求建立在一次TCP连接基础上,一次TCP请求至少产生一次HTTP请求



如果定义了大量名字，或者定义了非常长的名字，那可能需要在http配置块中使用server_names_hash_max_size和server_names_hash_bucket_size指令进行调整。
优先级：
确切的名字；
最长的以星号起始的通配符名字：*.start
最长的以星号结束的通配符名字：end.*；
第一个匹配的正则表达式名字（按在配置文件中出现的顺序）。

server_name  *.example.org; #通配符,只能在名字的起始处或结尾处包含一个星号,形如“.example.org”的特殊通配符，它可以匹配“example.org” 和 “*.example.org”。
server_name  ~^(?<domain>.+)\.example\.net$; #正则表达式,以波浪线“~”起,捕获组可以作为变量使用 root /sites/$domain 或者直接用捕获组 /sites/$2

error_log  /path/to/log  debug;
#只针对选定的客户端地址开启调试日志
events {
    debug_connection   192.168.1.1;
    debug_connection   192.168.10.0/24;
}






数据切分算法
主键求模：适用于数据增速慢的场景，但难以增加分片。增加分片时，建议在原有分片数量上，成倍数增加新分片。
主键范围切分：数据快速增长，易于增加分片。数据归档后，腾出的空间也无法被重复利用。
枚举值切分：归类存储数据，适合大多数业务。
日期切分：数据快速增长，易于增加分片。数据归档后，腾出的空间也无法被重复利用。

配置：按字段值切分
<tableRule name="sharding-by-intfile">
  <rule>
    <columns>sharding_id</columns>表字段
    <algorithm>hash-init</algorithm> 底层算法
  </rule>
</tableRule>

/mycat/conf/customer-hash-int.txt
<function name="io.mycat.route.function.PartitionByFileMap">
  <property name="mapFile">partition-hash-int.txt</property>
</function>


数据的数值=分片序号

sudo dpkg -i *.deb
sudo apt-get -f install

vim /etc/inputrc
set bell-style none

docker network create pxc-network
docker run -d -e MYSQL_ROOT_PASSWORD=root -e CLUSTER_NAME=cluster1  --net=pxc-network --name=node1  percona/percona-xtradb-cluster:5.7
docker run -d -e MYSQL_ROOT_PASSWORD=root -e CLUSTER_NAME=cluster1  --net=pxc-network -e CLUSTER_JOIN=node1 --name=node2 percona/percona-xtradb-cluster:5.7
docker run -d -e MYSQL_ROOT_PASSWORD=root -e CLUSTER_NAME=cluster1  --net=pxc-network -e CLUSTER_JOIN=node1 --name=node3 percona/percona-xtradb-cluster:5.7



docker exec -it node1 /usr/bin/mysql -uroot -proot
show status like 'wsrep%';


            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.8.0</version>
                <configuration>
                    <!-- 一般而言，target与source是保持一致的，但是，有时候为了让程序能在其他版本的jdk中运行(对于低版本目标jdk，源代码中不能使用低版本jdk中不支持的语法)，会存在target不同于source的情况 -->
                    <source>1.8</source> <!-- 源代码使用的JDK版本 -->
                    <target>1.8</target> <!-- 需要生成的目标class文件的编译版本 -->
                    <encoding>UTF-8</encoding><!-- 字符集编码，防止中文乱码 -->
                    <skipTests>true</skipTests><!-- 跳过测试 -->
                    <verbose>true</verbose>
                    <showWarnings>true</showWarnings>
                    <fork>true</fork><!-- 要使compilerVersion标签生效，还需要将fork设为true，用于明确表示编译版本配置的可用 -->
                    <executable><!-- path-to-javac --></executable><!-- 使用指定的javac命令，例如：<executable>${JAVA_1_4_HOME}/bin/javac</executable> -->
                    <compilerVersion>1.3</compilerVersion><!-- 指定插件将使用的编译器的版本 -->
                    <!-- 这下面的是可选项 -->
                    <meminitial>128m</meminitial><!-- 编译器使用的初始内存 -->
                    <maxmem>512m</maxmem><!-- 编译器使用的最大内存 -->
                    <compilerArgument>-verbose -bootclasspath ${java.home}\lib\rt.jar</compilerArgument><!-- 这个选项用来传递编译器自身不包含但是却支持的参数选项 -->
                </configuration>
            </plugin>

            
--module-path "C:\Programs\java\javafx15\lib" --add-modules=javafx.controls,javafx.fxml


import java.lang.annotation.Annotation;
import java.lang.reflect.Field;
import java.lang.reflect.InvocationTargetException;
import java.lang.reflect.Method;
import java.lang.reflect.Modifier;
import java.util.*;
import static java.lang.System.out;

class ListNode{
    public int val;
    public ListNode next;
}

class Tree {
    public Tree left;
    public Tree right;
    public void test(){

    }
}

public class App {

    public String findLongWord(String s, List<String> d){
        String longWord = "";
        for(String target : d){
            int l1 = longWord.length(), l2 = target.length();
            if(l1 > l2 || (l1 == l2 && longWord.compareTo(target) < 0)){
                continue;
            }
            if(isSubstr(s, target)){
                longWord = target;
            }
        }
        return longWord;
    }

    public boolean isSubstr(String s, String target){
        int i = 0;
        int j = 0;
        while(i < s.length() && j < target.length()){
            if(s.charAt(i) == target.charAt(j)){
                j++;
            }
            i++;
        }
        return j == target.length();
    }


    public List getIntersectionNode(LinkedList listA){

//        LinkedList a = listA;
//        LinkedList b = listB;
//        while(a != b){
//            a = (a == null)? listB : a.;
//        }

        System.out.println(listA.getFirst());
        return null;
    }

    public ListNode mergeTwoLists(ListNode l1, ListNode l2){
        if(l1 == null) return l2;
        if(l2 == null) return l1;
        if(l1.val < l2.val){
            l1.next = mergeTwoLists(l1.next, l2);
            return l1;
        }else{
            l2.next = mergeTwoLists(l1, l2.next);
            return l2;
        }
    }

    public int[] topKFrequent(int[] nums, int k) {

        Map<Integer, Integer> frequencyForNum = new HashMap<>();
        for (int num : nums) {
            frequencyForNum.put(num, frequencyForNum.getOrDefault(num, 0) + 1);
        }

        List<Integer>[] buckets = new ArrayList[nums.length + 1];
        for (int key : frequencyForNum.keySet()) {
            int frequency = frequencyForNum.get(key);
            if (buckets[frequency] == null) {
                buckets[frequency] = new ArrayList<>();
            }
            buckets[frequency].add(key);
        }

        List<Integer> topK = new ArrayList<>();
        for (int i = buckets.length - 1; i >= 0 && topK.size() < k; i--) {
            if (buckets[i] == null) {
                continue;
            }
            if (buckets[i].size() <= (k - topK.size())) {
                topK.addAll(buckets[i]);
            } else {
                topK.addAll(buckets[i].subList(0, k - topK.size()));
            }
        }

        int[] res = new int[k];
        for (int i = 0; i < k; i++) {
            res[i] = topK.get(i);
        }
        return res;
    }

    public int maxDepth(Tree root){
        if(root == null) return 0;
        return Math.max(maxDepth(root.left), maxDepth(root.right)) + 1;

    }

    public int maxDepth1(Tree root){
        if(root == null) return 0;
        int l = maxDepth1(root.left);
        int r = maxDepth1(root.right);
      //  if(Math.abs(l - r) > 1) this.result = false;
        return 1 + Math.max(l, r);

    }

    static void printClassInfo(Class cls) {

        System.out.println("Class name: " + cls.getName());
        System.out.println("Simple name: " + cls.getSimpleName());
        if (cls.getPackage() != null) {
            System.out.println("Package name: " + cls.getPackage().getName());
        }
        System.out.println("is interface: " + cls.isInterface());
        System.out.println("is enum: " + cls.isEnum());
        System.out.println("is array: " + cls.isArray());
        System.out.println("is primitive: " + cls.isPrimitive());

    }

    public static void main(String[] args) throws Exception {

        //Class cls = String.class;
        //Class cls2 = s.getClass();
        //Class cls3 = Class.forName("java.lang.String");

        // 获取String的Class实例:
        Class cls = String.class;
        // 创建一个String实例:
        //String s = (String) cls.getDeclaredConstructor().newInstance();


        Field f = String.class.getDeclaredField("value");
        f.setAccessible(true);
        f.getName(); // "value"

        f.getType(); // class [B 表示byte[]类型
        //f.get(Obj);
        //f.set();
        int m = f.getModifiers();
        //Modifier.isPublic(f.getModifiers());
        Method method = Person.class.getMethod("test");

List<String> s = List.of("app", "bbbb");

out.println(method.getAnnotation(Report.class));

System.exit(0);
            var tree = new Tree();
            try {

                tree.getClass().getMethod("test", new Class[]{String.class}).invoke(tree, new Object[]{"ss"});
            } catch (NoSuchMethodException e) {
                e.printStackTrace();
            } catch (IllegalAccessException e) {
                e.printStackTrace();
            } catch (InvocationTargetException e) {
                e.printStackTrace();
            }


        var a = new LinkedList<String>();
        a.add("abc");
        var obj = new App();
        obj.getIntersectionNode(a);

    }


}


一、Ctrl 快捷键
Ctrl + F 在当前文件进行文本查找 （必备）
Ctrl + R 在当前文件进行文本替换 （必备）
Ctrl + Z 撤销 （必备）
Ctrl + Y 删除光标所在行 或 删除选中的行 （必备）
Ctrl + X 剪切光标所在行 或 剪切选择内容
Ctrl + C 复制光标所在行 或 复制选择内容
Ctrl + D 复制光标所在行 或 复制选择内容，并把复制内容插入光标位置下面 （必备）
Ctrl + W 递进式选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展选中范围（必备）
Ctrl + E 显示最近打开的文件记录列表 （必备）
Ctrl + N 根据输入的 名/类名 查找类文件 （必备）
Ctrl + G 在当前文件跳转到指定行处
Ctrl + J 插入自定义动态代码模板 （必备）
Ctrl + P 方法参数提示显示 （必备）

Ctrl + Q 光标所在的变量 / 类名 / 方法名等上面（也可以在提示补充的时候按），显示文档内容
Ctrl + U 前往当前光标所在的方法的父类的方法 / 接口定义 （必备）
Ctrl + B 进入光标所在的方法/变量的接口或是定义处，等效于 Ctrl + 左键单击 （必备）
Ctrl + K 版本控制提交项目，需要此项目有加入到版本控制才可用
Ctrl + T 版本控制更新项目，需要此项目有加入到版本控制才可用
Ctrl + H 显示当前类的层次结构
Ctrl + O 选择可重写的方法
Ctrl + I 选择可继承的方法
Ctrl + + 展开代码
Ctrl + - 折叠代码
Ctrl + / 释光标所在行代码，会根据当前不同文件类型使用不同的注释符号 （必备）

Ctrl + [ 移动光标到当前所在代码的花括号开始位置
Ctrl + ] 移动光标到当前所在代码的花括号结束位置
Ctrl + F1 在光标所在的错误代码处显示错误信息 （必备）
Ctrl + F3 调转到所选中的词的下一个引用位置 （必备）
Ctrl + F4 关闭当前编辑文件
Ctrl + F8 在 Debug 模式下，设置光标当前行为断点，如果当前已经是断点则去掉断点
Ctrl + F9 执行 Make Project 操作
Ctrl + F11 选中文件 / 文件夹，使用助记符设定 / 取消书签 （必备）
Ctrl + F12 弹出当前文件结构层，可以在弹出的层上直接输入，进行筛选
Ctrl + Tab 编辑窗口切换，如果在切换的过程又加按上 delete，则是关闭对应选中的窗口

Ctrl + End 跳到文件尾
Ctrl + Home 跳到文件头
Ctrl + Space 基础代码补全，默认在 Windows 系统上被输入法占用，需要进行修改，建议修改为 Ctrl +逗号 （必备）
Ctrl + Delete 删除光标后面的单词或是中文句 （必备）
Ctrl +BackSpace 删除光标前面的单词或是中文句 （必备）
Ctrl +1,2,3…9 定位到对应数值的书签位置 （必备）
Ctrl + 左键单击 在打开的文件标题上，弹出该文件路径 （必备）
Ctrl + 光标定位按 Ctrl 不要松开，会显示光标所在的类信息摘要
Ctrl + 左方向键 光标跳转到当前单词 / 中文句的左侧开头位置 （必备）
Ctrl + 右方向键 光标跳转到当前单词 / 中文句的右侧开头位置 （必备）
Ctrl + 前方向键 等效于鼠标滚轮向前效果 （必备）
Ctrl + 后方向键 等效于鼠标滚轮向后效果 （必备）

二、Alt 快捷键
Alt + ` 显示版本控制常用操作菜单弹出层 （必备）
Alt + Q 弹出一个提示，显示当前类的声明 / 上下文信息
Alt + F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择 （必备）
Alt + F2 对于前面页面，显示各类浏览器打开目标选择弹出层
Alt + F3 选中文本，逐个往下查找相同文本，并高亮显示
Alt + F7 查找光标所在的方法 / 变量 / 类被调用的地方
Alt + F8 在 Debug 的状态下，选中对象，弹出可输入计算表达式调试框，查看该输入内容的调试结果
Alt + Home 定位 / 显示到当前文件的 Navigation Bar
Alt + Enter IntelliJ IDEA 根据光标所在问题，提供快速修复选择，光标放在的位置不同提示的结果也不同 （必备）
Alt + Insert 代码自动生成，如生成对象的 set / get 方法，构造函数，toString() 等 （必备）

Alt + 左方向键 切换当前已打开的窗口中的子视图，比如 Debug 窗口中有 Output、Debugger 等子视图，用此快捷键就可以在子视图中切换 （必备）
Alt + 右方向键 按切换当前已打开的窗口中的子视图，比如 Debug 窗口中有 Output、Debugger 等子视图，用此快捷键就可以在子视图中切换 （必备）
Alt + 前方向键 当前光标跳转到当前文件的前一个方法名位置 （必备）
Alt + 后方向键 当前光标跳转到当前文件的后一个方法名位置 （必备）
Alt +1,2,3…9 显示对应数值的选项卡，其中 1 是 Project 用得最多 （必备）

三、Shift 快捷键
Shift + F1 如果有外部文档可以连接外部文档
Shift + F2 跳转到上一个高亮错误 或 警告位置
Shift + F3 在查找模式下，查找匹配上一个
Shift + F4 对当前打开的文件，使用新 Windows 窗口打开，旧窗口保留
Shift + F6 对文件 / 文件夹 重命名
Shift + F7 在 Debug 模式下，智能步入。断点所在行上有多个方法调用，会弹出进入哪个方法
Shift + F8 在 Debug 模式下，跳出，表现出来的效果跟 F9 一样
Shift + F9 等效于点击工具栏的 Debug 按钮
Shift + F10 等效于点击工具栏的 Run 按钮
Shift + F11 弹出书签显示层 （必备）
Shift + Tab 取消缩进 （必备）
Shift + ESC 隐藏当前 或 最后一个激活的工具窗口
Shift + End 选中光标到当前行尾位置
Shift + Home 选中光标到当前行头位置
Shift + Enter 开始新一行。光标所在行下空出一行，光标定位到新行位置 （必备）
Shift + 左键单击 在打开的文件名上按此快捷键，可以关闭当前打开文件 （必备）
Shift + 滚轮前后滚动 当前文件的横向滚动轴滚动 （必备）

四、Ctrl + Alt 快捷键
Ctrl + Alt + L 格式化代码，可以对当前文件和整个包目录使用 （必备）
Ctrl + Alt + O 优化导入的类，可以对当前文件和整个包目录使用 （必备）
Ctrl + Alt + I 光标所在行 或 选中部分进行自动代码缩进，有点类似格式化
Ctrl + Alt + T 对选中的代码弹出环绕选项弹出层 （必备）
Ctrl + Alt + J 弹出模板选择窗口，将选定的代码加入动态模板中
Ctrl + Alt + H 调用层次
Ctrl + Alt + B 在某个调用的方法名上使用会跳到具体的实现处，可以跳过接口
Ctrl + Alt + V 快速引进变量
Ctrl + Alt + Y 同步、刷新
Ctrl + Alt + S 打开 IntelliJ IDEA 系统设置 （必备）
Ctrl + Alt + F7 显示使用的地方。寻找被该类或是变量被调用的地方，用弹出框的方式找出来

Ctrl + Alt + F11 切换全屏模式
Ctrl + Alt + Enter 光标所在行上空出一行，光标定位到新行 （必备）
Ctrl + Alt + Home 弹出跟当前文件有关联的文件弹出层
Ctrl + Alt + Space 类名自动完成
Ctrl + Alt + 左方向键 退回到上一个操作的地方 （必备）
Ctrl + Alt + 右方向键 前进到上一个操作的地方 （必备）
Ctrl + Alt + 前方向键 在查找模式下，跳到上个查找的文件
Ctrl + Alt + 后方向键 在查找模式下，跳到下个查找的文件

五、Ctrl + Shift 快捷键
Ctrl + Shift + F 根据输入内容查找整个项目 或 指定目录内文件 （必备）
Ctrl + Shift + R 根据输入内容替换对应内容，范围为整个项目 或 指定目录内文件 （必备）
Ctrl + Shift + J 自动将下一行合并到当前行末尾 （必备）
Ctrl + Shift + Z 取消撤销 （必备）
Ctrl + Shift + W 递进式取消选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展取消选中范围 （必备）
Ctrl + Shift + N 通过文件名定位 / 打开文件 / 目录，打开目录需要在输入的内容后面多加一个正斜杠 （必备）
Ctrl + Shift + U 对选中的代码进行大 / 小写轮流转换 （必备）
Ctrl + Shift + T 对当前类生成单元测试类，如果已经存在的单元测试类则可以进行选择 （必备）

Ctrl + Shift + C 复制当前文件磁盘路径到剪贴板 （必备）
Ctrl + Shift + V 弹出缓存的最近拷贝的内容管理器弹出层
Ctrl + Shift + E 显示最近修改的文件列表的弹出层
Ctrl + Shift + H 显示方法层次结构
Ctrl + Shift + B 跳转到类型声明处 （必备）
Ctrl + Shift + I 快速查看光标所在的方法 或 类的定义
Ctrl + Shift + A 查找动作 / 设置
Ctrl + Shift + / 代码块注释 （必备）
Ctrl + Shift + [ 选中从光标所在位置到它的顶部中括号位置 （必备）
Ctrl + Shift + ] 选中从光标所在位置到它的底部中括号位置 （必备）
Ctrl + Shift + + 展开所有代码 （必备）
Ctrl + Shift + - 折叠所有代码 （必备）

Ctrl + Shift + F7 高亮显示所有该选中文本，按 Esc 高亮消失 （必备）
Ctrl + Shift + F8 在 Debug 模式下，指定断点进入条件
Ctrl + Shift + F9 编译选中的文件 / 包 / Module
Ctrl + Shift + F12 编辑器最大化 （必备）
Ctrl + Shift + Space 智能代码提示
Ctrl + Shift + Enter 自动结束代码，行末自动添加分号 （必备）
Ctrl + Shift +Backspace 退回到上次修改的地方 （必备）
Ctrl + Shift +1,2,3…9 快速添加指定数值的书签 （必备）
Ctrl + Shift + 左键单击 把光标放在某个类变量上，按此快捷键可以直接定位到该类中 （必备）

Ctrl + Shift + 左方向键 在代码文件上，光标跳转到当前单词 / 中文句的左侧开头位置，同时选中该单词 / 中文句（必备） 
Ctrl + Shift + 右方向键 在代码文件上，光标跳转到当前单词 / 中文句的右侧开头位置，同时选中该单词 / 中文句（必备）
Ctrl + Shift + 前方向键 光标放在方法名上，将方法移动到上一个方法前面，调整方法排序 （必备）
Ctrl + Shift + 后方向键 光标放在方法名上，将方法移动到下一个方法前面，调整方法排序 （必备）

六、Alt + Shift 快捷键
Alt + Shift + N 选择 / 添加 task （必备）
Alt + Shift + F 显示添加到收藏夹弹出层 / 添加到收藏夹
Alt + Shift + C 查看最近操作项目的变化情况列表
Alt + Shift + I 查看项目当前文件
Alt + Shift + F7在 Debug 模式下，下一步，进入当前方法体内，如果方法体还有方法，则会进入该内嵌的方法中，依此循环进入
Alt + Shift + F9 弹出 Debug 的可选择菜单
Alt + Shift + F10 弹出 Run 的可选择菜单
Alt + Shift + 左键双击 选择被双击的单词 / 中文句，按住不放，可以同时选择其他单词 / 中文句 （必备）
Alt + Shift + 前方向键 移动光标所在行向上移动 （必备）
Alt + Shift + 后方向键 移动光标所在行向下移动 （必备）

七、Ctrl + Shift + Alt 快捷键
Ctrl + Shift + Alt + V 无格式黏贴 （必备）
Ctrl + Shift + Alt + N 前往指定的变量 / 方法
Ctrl + Shift + Alt + S 打开当前项目设置 （必备）
Ctrl + Shift + Alt + C 复制参考信息

八、其他快捷键
F2 跳转到下一个高亮错误 或 警告位置 （必备）
F3 在查找模式下，定位到下一个匹配处
F4 编辑源 （必备）
F7 在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则进入当前方法体内，如果该方法体还有方法，则不会进入该内嵌的方法中
F8 在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则不进入当前方法体内
F9 在 Debug 模式下，恢复程序运行，但是如果该断点下面代码还有断点则停在下一个断点上
F11 添加书签 （必备）
F12 回到前一个工具窗口 （必备）
Tab缩进 （必备）
ESC 从工具窗口进入代码文件窗口 （必备）
连按两次Shift 弹出 Search Everywhere 弹出层



mysql 启动失败：su: warning: cannot change directory to /nonexistent: No such file or directory

# Ubuntu
sudo service mysql stop
sudo usermod -d /var/lib/mysql/ mysql
sudo service mysql start


docker run -d --name web -v my-vol:/usr/share/nginx/html  nginx:1.9
--mount source=my-vol,target=/usr/share/nginx/html 

route add 172.17.0.0/16 mask 255.255.255.0 172.23.89.36 -p


apply、call、bind比较
那么 apply、call、bind 三者相比较，之间又有什么异同呢？何时使用 apply、call，何时使用 bind 呢。简单的一个栗子：

netsh interface portproxy delete v4tov4 listenport=80 listenaddress=*
netsh interface portproxy delete v4tov4 listenport=80 listenaddress=0.0.0.0

netsh interface portproxy add v4tov4 listenport=80 listenaddress=0.0.0.0 connectport=80 connectaddress=172.30.144.91 protocol=tcp
netsh interface portproxy add v4tov4 listenport=80 listenaddress=* connectport=80 connectaddress=172.30.144.91 protocol=tcp



var obj = {
    x: 81,
};
 
var foo = {
    getX: function() {
        return this.x;
    }
}
 
console.log(foo.getX.bind(obj)());  //81
console.log(foo.getX.call(obj));    //81
console.log(foo.getX.apply(obj));   //81
三个输出的都是81，但是注意看使用 bind() 方法的，他后面多了对括号。
也就是说，区别是，当你希望改变上下文环境之后并非立即执行，而是回调执行的时候，使用 bind() 方法。而 apply/call 则会立即执行函数。

再总结一下：
apply 、 call 、bind 三者都是用来改变函数的this对象的指向的；
apply 、 call 、bind 三者第一个参数都是this要指向的对象，也就是想指定的上下文；
apply 、 call 、bind 三者都可以利用后续参数传参；
bind 是返回对应函数，便于稍后调用；apply 、call 则是立即调用 。

func.call(this, arg1, arg2);
func.apply(this, [arg1, arg2])


箭头函数
箭头函数表达式的语法比函数表达式更简洁，并且没有自己的this，arguments，super或new.target。箭头函数表达式更适用于那些本来需要匿名函数的地方，并且它不能用作构造函数。


在箭头函数出现之前，每一个新函数根据它是被如何调用的来定义这个函数的this值：
如果是该函数是一个构造函数，this指针指向一个新的对象
在严格模式下的函数调用下，this指向undefined
如果是该函数是一个对象的方法，则它的this指针指向这个对象
This被证明是令人厌烦的面向对象风格的编程。


(param1, …, paramN) => { statements }
(param1, …, paramN) => expression 
() => expression
总结：只有一个参数或是一条语句时，小括号和大括号都是可选的。一条表达式表示返回。

//加括号的函数体返回对象字面量
params => ({foo: bar}) 

//支持剩余参数和默认参数
(param1, param2, ...rest) => { statements }
(param1 = defaultValue1, param2, …, paramN = defaultValueN) => {statements }

//同样支持参数列表解构
let f = ([a, b] = [1, 2], {x: c} = { x: 3}) => a + b + c; //等于 1 + 2 + 3

//参数解构
array.map(({ "length": len }) => len); 


function foo(n) {
  var f = () => arguments[0] + n; // 隐式绑定 foo 函数的 arguments 对象. arguments[0] 是 n,即传给foo函数的第一个参数
  return f();
}

function foo(arg) {
  var f = (...args) => args[0];
  return f(arg);
}


'use strict';
var obj = {
  b: () => {
    console.log(this); //Window 对象
  },
  c: function() {
    console.log( this); // Object 对象
  }
}

'use strict';
Object.defineProperty(obj, "name", {
  get: () => {
    console.log(this);//Window 对象
  }
});


(() => 'foobar')(); //返回 "foobar"

// 常规写法，let作用域
() => {let now = new Date(); }
console.log(now);  //not defined 

// 参数变量是局部变量
(now=new Date()) => "Good";
console.log(now);    //not defined

// 函数体内不使用 var 定义的变量是全局变量
() => { now = new Date(); }
console.log(now);  //ok


//箭头函数体的闭包（ i=0 是默认参数）
var Add = (i=0) => {return (() => (++i) )};
var v = Add();
v();           //1
v();           //2

//因为仅有一个返回，return 及括号（）也可以省略
var Add = (i=0)=> ()=> (++i);

箭头函数递归
var fact = (x) => ( x==0 ?  1 : x*fact(x-1) );


Promise 构造器主要用于包装返回值不是Promise 的函数
const promise1 = new Promise((resolve, reject) => {
  setTimeout(() => {
    resolve('foo');
  }, 300);
});

const myPromise =(new Promise(myExecutorFunc)).then(Fulfilled, Rejected)

const myPromise = (new Promise(myExecutorFunc))
  .then(FulfilledA)
  .then(FulfilledB)
  .catch(RejectedAny);


const promiseA = new Promise( (resolutionFunc,rejectionFunc) => {
    resolutionFunc(777);
});

promiseA.then( (val) => console.log("asynchronous logging has val:",val) );
console.log("immediate logging"); //这里可能会先于 then 执行

// produces output in this order:
// immediate logging
// asynchronous logging has val: 777

Promise.resolve(value)方法返回一个以给定值解析后的Promise 对象

function myAsyncFunction(url) {
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();
    xhr.open("GET", url);
    xhr.onload = () => resolve(xhr.responseText);
    xhr.onerror = () => reject(xhr.statusText);
    xhr.send();
  });
};


Ctrl + Shift + F 可以查找终端输出的内容。

inet 172.29.78.90  netmask 255.255.240.0  broadcast 172.29.79.255

route add 172.17.0.0 mask 255.255.0.0 172.29.78.90


  1111 0000
  0100 1110
  0100 0000
172.29.64.0

PUT /megacorp/_doc/1
{
    "first_name" : "John",
    "last_name" :  "Smith",
    "age" :        25,
    "about" :      "I love to go rock climbing",
    "interests": [ "sports", "music" ]
}

PUT /megacorp/_doc/2
{
    "first_name" :  "Jane",
    "last_name" :   "Smith",
    "age" :         32,
    "about" :       "I like to collect rock albums",
    "interests":  [ "music" ]
}

PUT /megacorp/_doc/3
{
    "first_name" :  "Douglas",
    "last_name" :   "Fir",
    "age" :         35,
    "about":        "I like to build cabinets",
    "interests":  [ "forestry" ]
}

轻量搜索
GET /megacorp/_doc/1
GET /megacorp/_search
GET /megacorp/_search?q=last_name:Smith

查询表达式搜索
GET /megacorp/_search
{
    "query" : {
        "match" : {
            "last_name" : "Smith"
        }
    }
}

GET /megacorp/_search
{
    "query" : {
        "bool": {
            "must": {
                "match" : {
                    "last_name" : "smith" 
                }
            },
            "filter": {
                "range" : {
                    "age" : { "gt" : 30 } 
                }
            }
        }
    }
}

全文搜索
GET /megacorp/_search
{
    "query" : {
        "match" : {
            "about" : "rock climbing"
        }
    }
}

短语搜索
#匹配同时包含 “rock” 和 “climbing” ，并且 二者以短语 “rock climbing” 的形式紧挨着的雇员记录。
GET /megacorp/_search
{
    "query" : {
        "match_phrase" : {
            "about" : "rock climbing"
        }
    }
}

高亮显示
GET /megacorp/_search
{
    "query" : {
        "match_phrase" : {
            "about" : "rock climbing"
        }
    },
    "highlight": {
        "fields" : {
            "about" : {}
        }
    }
}

挖掘出员工中最受欢迎的兴趣爱好
GET /megacorp/employee/_search
{
  "aggs": {
    "all_interests": {
      "terms": { "field": "interests" }
    }
  }
}



创建分片
PUT /blogs
{
   "settings" : {
      "number_of_shards" : 3, //主分片数量
      "number_of_replicas" : 1 //每个主分版的副本数量
   }
}
查看集群健康
GET /_cluster/health



new start
PUT /customer/_doc/1
{
  "name": "John Doe"
}
GET /customer/_doc/1



sudo apt install -y curl wget openssl  make cmake gcc g++

php 依赖
sudo apt update
sudo apt install -y \
 autoconf \
 dpkg-dev \
 file \
 g++ \
 gcc \
 libc6-dev \
 make \
 pkg-config \
 re2c \
 ca-certificates \
 curl \
 xz-utils \
 libargon2-dev \
 libcurl4-openssl-dev \
 libedit-dev \
 libonig-dev \
 libsodium-dev \
 libsqlite3-dev \
 libssl-dev \
 libxml2-dev \
 zlib1g-dev \
 libfreetype6-dev \
 libjpeg-turbo8-dev \
 libpng-dev \
 libzip-dev \

 


php7.3

./configure \
  --prefix=/d/usr/php \
  --with-config-file-path=/d/usr/php/etc \
  --with-mysqli \
  --with-pdo-mysql \
  --with-zlib \
  --with-curl \
  --with-gettext \
  --with-openssl \
  --with-mhash \
  --with-pear   \
  --enable-zip \
  --with-readline \
  --with-libedit  \
  --enable-fpm \
  --enable-xml \
  --enable-bcmath \
  --enable-shmop \
  --enable-sysvsem \
  --enable-mbregex \
  --enable-mbstring \
  --enable-ftp \
  --enable-sockets \
  --enable-soap \
  --enable-pcntl \
  --enable-debug \
  --with-gd \
  --with-freetype-dir \
  --with-webp-dir \
  --with-png-dir \
  --with-jpeg-dir \
  --with-pic \
  --enable-mysqlnd \
  --with-password-argon2 \
  --with-sodium=shared       
 
install libgd-dev  libzstd-dev   libpcre3-dev
install libxml2 

software=nginx1.9 && ./configure \
 --prefix=/d/usr/$software \
 --conf-path=/d/etc/$software/nginx.conf \
 --with-http_ssl_module \
 --with-select_module \
 --with-poll_module \
 --with-threads \
 --with-file-aio \
 --with-debug    



git init
git add README.md
git commit -m "first commit"
git branch -M main
git remote add origin git@github.com:zbseoag/develop.git
git push -u origin main

powershell
echo $profile

禁用响铃
sudo vi /etc/inputrc 文件中取消注释 set bell-style none


最后一个参数 !$ 
!! 上一条命令

composer create-project laravel/laravel example-app
cd example-app
php artisan serve

docker network create -d bridge localhost
docker run --name work --network localhost -p 80:80 -v /desktop/cnasanx/wwwroot:/var/www/html php:5.3.29-apache
docker run --name mysql5.6 --network localhost -p 3306:3306  -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.6

ServerName localhost
docker.open work /etc/apache2/apache2.conf

php -S 172.17.02:8081 -t /home/www-data


curl -X POST 'localhost:9200/<PATH>?<QUERY_STRING>' -d '<BODY>'



ubuntu2004.exe help
ubuntu2004.exe config --default-user root
https://github.com/xianyunyh/PHP-Interview
https://github.com/opsnull/follow-me-install-kubernetes-cluster
https://github.com/OMGZui/noteBook
https://github.com/shuzheng/zheng
https://github.com/lin-xin/vue-manage-system

官网: http://googlehelper.net/


sudo curl -L "https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$(uname -s)-$(uname -m)" -o /srv/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose


C:\Users\zbseoag\AppData\Roaming\JetBrains\PhpStorm2020.3\ssl\cacerts


cd /etc/init.d/
vim my.init.script.sh
chmod a+x my.init.script.sh
update-rc.d my.init.script.sh defaults 90

移除Ubuntu开机脚本
sudo update-rc.d -f my.init.script.sh remove


删除 snapd
sudo apt autoremove --purge snapd

dpkg -i|--install 		<file.deb> 		安装 dbg 包
dpkg -L|--listfiles 		<package>  		列出属于指定软件包的文件
dpkg -l|--list 			<package>		简明列出软件包状态
dpkg -r|--remove 		<package>		仅卸载软件
dpkg -P|--purge 		<package>		卸载软件清理配置
dpkg -S|--search		<package>		查找包中包含的文件
dpkg -c|--contents		<file.deb>		查看 deb 包内容
dpkg --get-selections 		[package]		查找包名


apt list	[package]	根据名称查找软件包
apt search	<package>	搜索软件包描述
apt show	<package>	显示软件包细节
apt install 	<package> 	安装软件包
apt reinstall	<package>	重装软件包
apt update			更新件包列表
apt upgrade			安装软件更新
apt remove 	<package>	卸载软件包
apt purge	<package>	卸载并清理
apt autoremove			自动卸载所有自动安装的无用软件包
apt autoclean			自动清理已下载的旧包文件
apt autopurge			自动卸载并清理


彻底卸载gedit
$ sudo  apt-get  purge gedit gedit-plugins
$ sudo apt-get autoremove

CTRL  + A  |  E 移光标于首尾
CTRL  + U  |  K 删光标前后所有字符
CTRL  + H  |  D 删光标前后一个字符
CTRL  + LEFT |  RIGHT 光标左右移动一个单词位
CTRL  + S | Q	暂停与继续屏幕输出
CTRL  + & | Y 撤消与重复
CTRL  + W 删除光标前一个单词
CTRL  + T	交换前后一个字符
CTRL  + Z 转至后台运行
CTRL  + D 结束输入或关闭终端
CTRL  + L 清屏
CTRL  + R 搜索历史命令
ALT + . 补全上一条命令最后一个参数

备用快捷键：
CTRL  + B | F  代替左右键
CTRL  + P | N	 代替上下键
ESC + .   补全上一条命令最后一个参数


apt -s autoremove
vim /etc/docker/daemon.json
{
    "registry-mirrors":["http://hub-mirror.c.163.com"]
}

curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh


sudo passwd root
sudo apt purge firefox firefox-locale-en firefox-locale-zh-hans 

sudo apt install gnome-tweak-tool gnome-shell-extensions
sudo apt install gnome-shell-extension-dash-to-panel 

sudo vim /etc/default/grub #修改 GRUB_TIMEOUT
sudo update-grub
   
1. 从wheel组中删除 test用户
gpasswd wheel -d test

sudo usermod -aG root $USER

RUN sed -i "s/archive.ubuntu./mirrors.aliyun./g" /etc/apt/sources.list
RUN sed -i "s/deb.debian.org/mirrors.aliyun.com/g" /etc/apt/sources.list
RUN sed -i "s/security.debian.org/mirrors.aliyun.com\/debian-security/g" /etc/apt/sources.list
RUN sed -i "s/httpredir.debian.org/mirrors.aliyun.com\/debian-security/g" /etc/apt/sources.list


docker build  -t zbseoag/php:8.0 .

RUN sed -i 's#http://archive.ubuntu.com#http://mirrors.163.com#g' /etc/apt/sources.list


主从复制
replicaof <host> <port>
replicaof no one #停止
role #返回实例在复制中担任的角色


客户端与服务器
auth password #连接密码,是 requirepass 配置项
quit #退出
info [all|default|section] #以一种易于解释（parse）且易于阅读的格式
shutdown [save|nosave] :关闭 redis 服务器,不给参数,就按配置文件中的持久化策略
time #返回当前服务器时间
client setname connection-name #设置连接名, 空字符串表示移除名字
client getname #返回连接名
client kill ip:port #关闭指定的客户端
client list #返回所有连接到服务器的客户端信息和统计数据



python  -m pip install --upgrade pip
pip install requests


配置选项
config set parameter value
config get parameter
config resetstat #重置 info 命令中的某些统计数据
config rewrite #将运行中的配置重写回配置文件






swoole.use_shortname=On/Off 来开启 / 关闭短名

创建协程
//go() = Swoole\Coroutine::create
go(function () {
    co::sleep(0.5);
});

通道操作
//Coroutine\Channel as chan
$c = new chan(1);
$c->push($data);

延迟执行
//defer() = Swoole\Coroutine::defer
defer(function () use ($db) {
    $db->close();
});

协程 System API
Swoole\Coroutine => Swoole\Coroutine\System





Redis 调试

ping
echo
object subcommand [arguments [arguments]]
object refcount <key> 返回给定 key 引用所储存的值的次数。此命令主要用于除错。
object encoding <key> 返回给定 key 锁储存的值所使用的内部表示(representation)。
object idletime <key> 返回给定 key 自储存以来的空闲时间(idle， 没有被读取也没有被写入)，以秒为单位。


slowlog 的配置
slowlog-log-slower-than 多少微秒以上算做慢查询  
slowlog-max-len 最大记录条数

#最新的日志会最先被打印,日志 id 在 redis 服务器重启的时候才会重置
slowlog get #查看所有记录
slowlog get length #显示指固定条数
slowlog len #当前总条数
slowlog reset #清空
monitor #监控 redis 服务器接收到的命令
debug object key #调试命令，它不应被客户端所使用
debug segfault #执行一个不合法的内存访问从而让 redis 崩溃，仅在开发时用于 bug 模拟


para meter  [pəˈræ  mɪtə(r)]
proxy [ˈprɒk si]


参数名称	用途
-server	此标志用于控制代理是运行于服务器/客户端模式，每个 Consul 集群至少有一个服务器，正常情况下不超过5个，使用此标记的服务器参与 Raft一致性算法、选举等事务性工作
-client	表示 Consul 绑定客户端接口的IP地址，默认值为：127.0.0.1，当你有多块网卡的时候，最好指定IP地址，不要使用默认值
-bootstrap-expect	预期的服务器集群的数量，整数，如 -bootstrap-expect=3，表示集群服务器数量为3台，设置该参数后，Consul将等待指定数量的服务器全部加入集群可用后，才开始引导集群正式开始工作，此参数必须与 -server 一起使用
-data-dir	存储数据的目录，该目录在 Consul 程序重启后数据不会丢失，指定此目录时，应确保运行 Consul 程序的用户对该目录具有读写权限
-node	当前服务器在集群中的名称，该值在整个 Consul 集群中必须唯一，默认值为当前主机名称
-bind	Consul 在当前服务器侦听的地址，如果您有多块网卡，请务必指定一个IP地址（IPv4/IPv6)，默认值为：0.0.0.0，也可用使用[::]
-datacenter	代理服务器运行的数据中心的名称，同一个数据中心中的 Consul 节点必须位于同一个 LAN 网络上
-ui	启用当前服务器内部的 WebUI 服务器和控制台界面
-join	该参数指定当前服务器启动时，加入另外一个代理服务器的地址，在默认情况下，如果不指定该参数，则当前代理服务器不会加入任何节点。可以多次指定该参数，以加入多个代理服务器，
-retry-join	用途和 -join 一致，当第一次加入失败后进行重试，每次加入失败后等待时间为 30秒
-syslog	指定此标志意味着将记录 syslog，该参数在 Windows 平台不支持


// 172.16.1.218
consul agent -server -ui -bootstrap-expect=3 -data-dir=/home/zbseoag/consul -node=agent-1 -client=127.0.0.1 -bind=127.0.0.4 -datacenter=dc1

// 172.16.1.219
consul agent -server -ui -bootstrap-expect=3 -data-dir=/home/zbseoag/consul -node=agent-2 -client=127.0.0.2 -bind=127.0.0.5 -datacenter=dc1 -join 127.0.0.4

// 172.16.1.220
consul agent -server -ui -bootstrap-expect=3 -data-dir=/home/zbseoag/consul -node=agent-3 -client=127.0.0.3 -bind=127.0.0.6 -datacenter=dc1 -join 127.0.0.4



eval script keycount key [key ...] arg [arg ...] 执行 lua 脚本。
evalsha sha1 keycount key [key ...] arg [arg ...] 执行 lua 脚本。
script exists script [script ...] 查看指定的脚本是否已经被保存在缓存当中。
script flush 从脚本缓存中移除所有脚本。
script kill 杀死当前正在运行的 lua 脚本。
script load script 将脚本 script 添加到脚本缓存中，但并不立即执行这个脚本。

删除名为登录的密钥环，重启，打开chrome 显示对话框时，什么都不输入直接点继续。

sudo vim /etc/sudoers
在 %sudo	ALL=(ALL:ALL) ALL 添加  username <TAB键> ALL=(ALL) NOPASSWD: ALL
zbseoag   ALL=(ALL) NOPASSWD: ALL

#[[ "${colors[@]}" =~ $color ]]

git reset
我的电脑
win + i ：打开设置
Win + 1、2、3 ：打开任务栏的程序
Shift + 单击  ：打开任务栏程序的新窗口
win + pause
Ctrl + Shift + Esc 任务管理器
win + e   资源管理器
Win+A 操作中心

sh zkServer.sh start
sh zkCli.sh

指定脚本解释器
在 shell 脚本，#! 告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 解释器。#! 被称作shebang

:<<EOF
echo '这是多行注释'
echo '这是多行注释'
EOF

echo -e "YES\c" # -e 开启转义 \c 不换行
readonly rword
字符长度： ${#text}

text="heaao"
echo `expr index "${text}" aa` #查找 aa 在 heaao 中的起始位置。

nums=([2]=2 [0]=0 [1]=1)
colors=(red yellow "dark blue")

扩展数组
colors=(1 2 3)
colors=(a "${colors[@]}" b c)



printf "%-5s %-5.2f \n" Name 100.254
- 左对齐
5 数字表示字符长度，浮点数可以带小数（%5.2f），表示保留小数位
s 字符串
f 浮点数


echo -e "\033[前;背;特效m 字符串内容 \033[0m"
echo -e "\033[0;31;5m string is here \033[0m"
特效：0 关闭、1 设置高亮度、4 下划线、5 闪烁、7 反显

let sum=one+=10
sum=$[no1 + no2]
sum=$((no1 + no2 + 8))

sum=`expr 2 % 3`
sum=$(expr $one \* 5) #乘法

echo "scale=4;3/8" | bc
echo "obase=2;$num" | bc

num=11000001
echo "obase=10;ibase=2;$num" | bc  #二进制数转十进制


echo "10^10" | bc
echo "sqrt(100)" | bc


export 变量名...
export 变量名=变量值 [...变量名n=变量值n]

unset 变量名


常见的环境变量

$USER 查看账户信息
$logname 登录相关信息
$UID
$Shell
$HOME 家目录
$pwd
$PATH 用户所输入的命令是在哪些目录中查找
$PS1
$PS2
$RANDOM 随机数

$# ：命令行中位置参数的个数
$* ：所有位置参数的内容
$@ ：所有位置参数的内容
$? ：上一条命令执行后返回的状态，当返回状态值为0时表示执行正常，非0表示执行异常或出错
$$ ：当前所在进程的进程号
$! ：后台运行的最后一个进程号
$0 ：当前执行的进程/程序名


条件测试
test 条件表达式
[ 条件表达式 ]

-d：测试是否为目录
-e：测试目录或文件是否存在
-f：测试是否为文件
-r：测试当前用户是否有权限读取
-w：测试当前用户是否有权限写入
-x：测试当前用户是否可执行该文件
-L：测试是否为符号链接文件
-nt：最后修改时间 new than 
-ot：最后修改时间 old than


字符串比较
[ 字符串1 =、!= 、<、> 字符串2 ]
[ -z|-n 字符串的空与非空 ]


整数值比较
[ 整数1 操作符 整数2 ]
-eq：等于
-ne：不等于
-gt：大于
-lt：小于
-le：小于等于
-ge：大于等于

逻辑测试
[ 表达式1 ] 操作符 [ 表达式2 ] ...

-a 或 &&：与
-o 或 ||：或
!：否


if [ null ];then

elif [ null ];then

else
 
fi


for arg in elem1 elem2 ... elemN
do
  
done

for(( i=1; i<=5; i++ ))
do
  
done 


while [ $i -le 10 ]
do

 i=`expr $i + 1`

done

while [[ ${x} -lt 10 ]]; do
  echo $((x * x))
  x=$((x + 1))
done


case "$1" in
  'start'|'-start') echo stop;;
  *) echo default;;
esac


until [ $var -gt 10 ]
do
  echo $var
  var=$(( $var + 1 ))
done 


大括号扩展
大括号扩展让生成任意的字符串成为可能。它跟 文件名扩展 很类似，举个例子：

echo beg{i,a,u}n ### begin began begun
大括号扩展还可以用来创建一个可被循环迭代的区间。

echo {0..5} ### 0 1 2 3 4 5
echo {00..8..2} ### 00 02 04 06 08


bash -x script.sh
sh -x script.sh

set -x：在执行时候显示参数和命令。
set +x：禁止调式
set -v：当命令进入读取时候显示输入
set +v：禁止打印输入

for i in {1..5}
do
  set -x
    echo $i
  set +x
done

使用shebang调式方法
#!/bin/bash -xv


data="111,222,333,444,555,666"
old=$IFS  #定义一个变量为默认IFS
IFS=,        #设置IFS为逗号
for i in $data
do
 echo $i
done
IFS=$old  #还原

环境变量设置

变量名：JAVA_HOME
变量值：C:\Program Files\Java\jdk1.7.0

//这里是你JDK的安装路径，可以更换
变量名：CLASSPATH
变量值：.;%JAVA_HOME%\lib\dt.jar;%JAVA_HOME%\lib\tools.jar; //记得前面有个"."
变量名：Path
变量值：%JAVA_HOME%\bin;%JAVA_HOME%\jre\bin;




离职原因：
公司是做跨境电商，受疫情影响，进出口都受不到同程度影响，我所在的进口事撤消了部分业务线。我本人也想换个环境，就出来了。


高级到资深技术开发



成员变量和方法作用域
对于成员变量和方法的作用域，public，protected，private以及不写之间的区别：

public : 表明该成员变量或者方法是对所有类或者对象都是可见的,所有类或者对象都可以直接访问

private : 表明该成员变量或者方法是私有的,只有当前类对其具有访问权限,除此之外其他类或者对象都没有访问权限.子类也没有访问权限.

protected : 表明成员变量或者方法对类自身,与同在一个包中的其他类可见,其他包下的类不可访问,除非是他的子类

default : 表明该成员变量或者方法只有自己和其位于同一个包的内可见,其他包内的类不能访问,即便是它的子类


Java中只有值传递，只不过传递的内容是对象的引用。

8种基本数据类型
Java中有8种基本数据类型分为三大类。

字符类型 char
布尔类型 boolean
数值类型 byte、short、int、long、float、double

Java中的数值类型都是有符号的。
Java中还存在另外一种基本类型void，它也有对应的包装类 java.lang.Void，不过我们无法直接对它们进行操作。

基本数据类型转换成包装类叫装箱
包装类转换成基本数据类型叫拆箱



三目运算符，第二和第三位操作数分别是基本类型和对象，对象会进行拆箱操作，由于该对象为null，所以在拆箱过程中调用null.booleanValue()的时候就报了NPE。

Map<String,Boolean> map =  new HashMap<String, Boolean>();

//这里会报错
Boolean b = (map!=null ? map.get("test") : false);
//改成
Boolean b = (map!=null ? map.get("test") : Boolean.FALSE);


在Java中，== 比较的是对象，而 equals 比较的是值。



C#
虚方法才能被子类重写。


作为整体参与运算的一串二进制的位数称为字长，它一般是8的倍数，如：8位，16位，32位。
一个数在计算机上的表示形式叫作机器数，在字长为8位时，5的机器数是00000101。

在计算机中，5与-5 的原码相加不等于0

原码表示法，编码简单，但运算时要单独考虑符号位和判别0，增加了运算规则的复杂性。
补码：正数的原、反、补码相同，负数补码等于反码加1

编译：用编译器把高级语言编写的源程序翻译成用机器指令表示的目标代码，再通过连接器将目标程序与相关库连接成一个完整的可执行程序。
优点：执行速度快，产生的可执行程序可以独立运行。

解释：用解释器将源程序进行翻译，解释一句，执行一句，直到结束。
优点：移植到不同平台时，不必修改源程序，只要有跨平台的解释器即可。


c primer plus
c++ primer plus

所有寄存器都是16位的。


默认的Windows磁盘在WSL的访问方式是/mnt开头，可能不太方便，我们下面更换成是/开头的吧。

打开这个文件：
sudo vim /etc/wsl.conf
添加下面三行内容，并保存此文件：
[automount] 
root = / 
options = "metadata"




debug
r 查看、改变寄存器内容
r ax 123

d 查看内存中的内容
d 2000:0

e 改变内在中的内容
e 2000:0 1 2 3
e 2000:0 回车 1 空格 2空格...回车

u 将机器指令翻译成汇编指令
e 2000:0 b8 23 01 bb 03 00 89 d8 01 d8
d 2000:0 f
u 2000:0

a 通过汇编指令写入机器指令
a 073f:0100
mov ax, 0123
mov bx, 0003
mov ax, bx
add ax, bx

t 执行机器指令

jmp 段地址：偏移地址


将段地址送入DS:数据->一般寄存器->段寄存器
mov bx 1000
mov ds, bx

定义 1000 到 1010 的16个字段空间为栈
mov ax 1000
mov ss, ax
mov sp, 0010

物理地址 = 段地址 X 16 + 偏移地址
将一级内存单元定义为一个段
可以将起始地址为16的倍数，最大长度为64的一组地址连续的内在定义为一个段。
将一段内存定义为一个段，用一个段地址指示段，用偏移地址访问段内的单元。

数据段（ds），代码段（cs：ip），栈段（ss：sp）

汇编程序：包含汇编指令和伪指令的文本。




sudo dpkg -i mongodb-org-server_4.4.1_amd64.deb
sudo dpkg -i mongodb-org-shell_4.4.1_amd64.deb

sudo service mongod start
sudo service mongod status

mongo
show dbs
use <dbname>
db.createCollection(<table>)
show tables
db.<table>.drop()
db.<table>.remove({})
db.<table>.insert({title: 'MongoDB 教程',  tags: ['mongodb', 'NoSQL'],likes: 100 })
db.<table>.find().pretty()
db.<table>.update({ "money": { $gt: 1 } } , { $set: { "by": "OK"} } );


Mysql 8.0 版本
use mysql;
update user set host='%' where user='root';

#查看 validate_password 密码验证插件是否安装
show VARIABLES LIKE 'validate_password%';
set global validate_password.policy=0;
set global validate_password.length=3;

#重新设置密码： 
ALTER USER 'root'@'%' IDENTIFIED BY '123456';
FLUSH PRIVILEGES;



redis:

 ### cluster 命令  ###

cluster addslots slot [slot ...]
添加哈希槽

cluster delslots slot [slot ...]
删除哈希槽


cluster count-failure-reports node-id
查看指定节点的故障报告个数


cluster countkeysinslot slot
返回连接节点负责的指定hash slot的key的数量


cluster failover [force|takeover]
在 slave 节点执行，让slave节点进行一次人工故障切换


cluster forget node-id
从群集节点的节点信息列表中移除指定节点

cluster getkeysinslot slot count
返回存储在连接节点的指定hash slot里面的key的列表

cluster info
关于redis集群的参数


cluster keyslot key
返回一个整数，用于标识指定键所散列到的哈希槽


cluster meet ip port

cluster nodes 

cluster replicas node-id
列出指定节点的副节点


cluster replicate node-id
重新配置一个节点成为指定master的salve节点


cluster reset [hard|soft]


cluster saveconfig
强制保存 nodes.conf 到磁盘


cluster set-config-epoch config-epoch
为一个全新的节点设置指定的config epoch


cluster setslot slot importing|migrating|stable|node [node-id]


cluster slaves node-id
列出指定节点的所有slave节点


cluster slots
返回哈希槽和redis实例映射关系


readonly
开启与 cluster 从节点连接的读请求


readwrite
禁止与redis cluster从节点连接的读请求


### connection 命令 ###

auth password
请求密码

echo message
返回消息

ping [message] ：测试一个连接

quit ：关闭连接


select index ：选择一个数据库，下标值从0开始

swapdb index1 index2 ：交换数据库


### 哈希 命令 ###

hset key field value ： 添加或修改一个键值对到哈希集

hsetnx key field value ： 绝对添加一个键值对到哈希集

hmset key field value [field value ...] ： 批量添加键值对到哈希集

hmget key field [field ...]  ：从哈希集中获取多个字段的值

hkeys key ： 返回所有字段名

hvals key ： 返回所有字段值

hlen key ：哈希集中字段的数量


hstrlen key field ： 返回字段值的长度

hdel key field [field ...] ：从哈希中移除指定的域

hexists key field ：field是否存在

hget key field ： 返回哈希集中的字段值

hgetall key ： 返回指定的哈希集

hincrby key field increment ：哈希字段通过指定整型值自增

hincrbyfloat key field increment ：哈希字段通过指定浮点值自增

hscan key cursor [match pattern] [count count]


###### key1

del key [key ...] ： 批量删除key

dump key ： 序列化给定 key 

exists key [key ...] ： 返回key是否存在

expire key seconds ：设置key的过期时长

pexpire key milliseconds ：设置 key 毫秒级的过期时长

expireat key timestamp ：设置 key 的过期时间点

pexpireat key milliseconds-timestamp ：设置 key 毫秒级的过期时间点

keys pattern ：按正则表达式搜索key

pttl key ： 返回 key 毫秒级的剩余生存时间

ttl key

type key

unlink key [key ...] ： 异步删除

wait numslaves timeout ： 此命令阻塞当前客户端，直到所有以前的写命令都成功的传输和指定的slaves确认

migrate host port key destination-db timeout [copy] [replace] ： 将 key 原子性地从当前实例传送到目标实例的指定数据库上，一旦传送成功， key 保证会出现在目标实例上，而当前实例上的 key 会被删除。

move key db ： 把当前库中的key移动到指定库，不会覆盖


object subcommand [arguments [arguments ...]] 

persist key ：移除给定 key 的过期时间

randomkey ： 返回一个随机的key

rename key newkey ： 重命名，新名覆盖

renamenx key newkey ：安全的重命名

restore key ttl serialized-value [replace] ： 反序列化给定的序列化值，并将它和给定的 key 关联

scan cursor [match pattern] [count count]

scan 命令用于迭代当前数据库中的key集合。
sscan 命令用于迭代set集合中的元素。
hscan 命令用于迭代hash类型中的键值对。
zscan 命令用于迭代sortset集合中的元素和元素对应的分值


sort key [by pattern] [limit offset count] [get pattern] [asc|desc] [alpha] destination

touch key [key ...] ： 修改指定 key 最后访问时间


npm -v
npm install npm -g
npm update <package> -g
npm install -g --force <package-name>
npm update <package-name>
npm view <package-name>
npm info <package-name>
npm show <package-name>
npm config get cache
npm cache clean
npm install --cache-min 9999999 <package-name> 从缓存安装
npm install --cache-min Infinity <package-name>
npm-cache install <package-name>

npm list -g
npm list <package-name>
npm uninstall <package-name>
npm ls
npm search <package-name>

npm init
npm adduser
npm publish
npm help <command>
npm unpublish <package>@<version>

在package.json所在目录下使用npm install . -g可先在本地安装当前命令行程序，可用于发布前的本地测试。

npm install -g @vue/cli
vue --version
vue create hello-world
cd hello-world
npm run serve
vue create --help

npm install -g @vue/cli-service-global
在开发环境模式下零配置为 .js 或 .vue 文件启动一个服务器
vue serve [options] [entry]
Options:
  -o, --open  打开浏览器
  -c, --copy  将本地 URL 复制到剪切板
  -h, --help  输出用法信息


在生产环境模式下零配置构建一个 .js 或 .vue 文件
vue build [options] [entry]
Options:
  -t, --target <target>  构建目标 (app | lib | wc | wc-async, 默认值：app)
  -n, --name <name>      库的名字或 Web Components 组件的名字 (默认值：入口文件名)
  -d, --dest <dir>       输出目录 (默认值：dist)
  -h, --help             输出用法信息



创建一个由 `vue-cli-service` 提供支持的新项目
vue create [options] <app-name>
选项：
  -p, --preset <presetName>       忽略提示符并使用已保存的或远程的预设选项
  -d, --default                   忽略提示符并使用默认预设选项
  -i, --inlinePreset <json>       忽略提示符并使用内联的 JSON 字符串预设选项
  -m, --packageManager <command>  在安装依赖时使用指定的 npm 客户端
  -r, --registry <url>            在安装依赖时使用指定的 npm registry
  -g, --git [message]             强制 / 跳过 git 初始化，并可选的指定初始化提交信息
  -n, --no-git                    跳过 git 初始化
  -f, --force                     覆写目标目录可能存在的配置
  -c, --clone                     使用 git clone 获取远程预设选项
  -x, --proxy                     使用指定的代理创建项目
  -b, --bare                      创建项目时省略默认组件中的新手指导信息
  -h, --help                      输出使用帮助信息

vue ui : 以图形化界面创建和管理项目


npm install -g cnpm --registry=https://registry.npm.taobao.org
cnpm sync <package-name>


npm install -g @vue/cli-service




流畅的python
go 语言高级编程


Export-Alias -Path "alias.ps1" -As Script
Add-Content -Path $Profile -Value (Get-Content alias.ps1)
$S = New-PSSession -ComputerName Server01
Invoke-Command -Session $S -FilePath .\alias.ps1



javac HelloWorld.java
java HelloWorld 

go run test.go
go build hello.go



# 构建项目中的服务容器
docker-compose build [options] [service]
--force-rm 删除构建过程中的临时容器
--no-cache 构建镜像过程中不使用 cache（这将加长构建过程）
--pull 始终尝试通过 pull 来获取更新版本的镜像



给容器指定一个固定 IP 地址，而不是每次重启容器 IP 地址
$ docker network create -d bridge --subnet 172.25.0.0/16 my-net
$ docker run --network=my-net --ip=172.25.3.3 -itd --name=my-container busybox



sysctl -w net.ipv4.ip_forward=1


docker logs -f <container>

docker volume create my_vol
docker volume ls
docker volume inspect my_vol
docker volume rm my_vol
docker volume prune #清理无主的数据卷

docker inspect web


# 加载数据卷到容器 /webapp 目录
-v my_vol:/webapp
--mount source=my_vol,target=/webapp

# 加载主机 /host/webapp 目录到容器 /webapp 目录
-v /host/webapp:/webapp 
--mount type=bind,source=/host/webapp,target=/webapp,readonly

# 主机挂载单个文件到容器中
-v $HOME/.bash_history:/root/.bash_history \
--mount type=bind,source=$HOME/.bash_history,target=/root/.bash_history 


-P 表示随机映射一个 49000~49900 的端口到内部容器开放的网络端口
-p 8080:80
-p 127.0.0.1:5000:5000 # 指定地址和端口
-p 127.0.0.1::5000 # 指定地址任意端口
-p 127.0.0.1:5000:5000/udp # 指定 udp 方式

# 当前映射的端口配置
docker port <container> <port>


docker network create -d bridge  <network>
-d 网络类型: bridge | overlay

docker run --network <network>


container # ping <container>


配置全部容器的 DNS 编辑 /etc/docker/daemon.json 文件
# 每次启动的容器 DNS 自动配置为 114.114.114.114 和 8.8.8.8
{
  "dns" : [
    "114.114.114.114",
    "8.8.8.8"
  ]
}

证明其已经生效
$ docker run -it --rm ubuntu:18.04  cat etc/resolv.conf

nameserver 114.114.114.114
nameserver 8.8.8.8


--hostname
--dns
--dns-search=DOMAIN 设定搜索域，当设定搜索域为 .example.com 时，在搜索一个名为 host 的主机时，DNS 不仅搜索 host，还会搜索 host.example.com


docker run --restart=always -d --name=mysql_1 -e MYSQL_ROOT_PASSWORD=123456 -p 3306:3306 -p 33060:33060 mysql:8.0.20





vim /etc/docker/daemon.json
{
  "registry-mirrors": [
    "https://hub-mirror.c.163.com"
  ]
}

sudo systemctl daemon-reload
sudo systemctl restart docker

docker pull ubuntu
docker run -it --rm ubuntu bash
root@e7009c6ce357:/# cat /etc/os-release
root@e7009c6ce357:/# exit

docker image ls
docker image ls -a
docker image ls -q
docker image ls <image>
#镜像摘要
docker image ls --digests
docker image ls --filter since=<image>
docker image ls --filter label=com.example.version=0.1

# 列出镜像结果，并且只包含镜像ID和仓库名
docker image ls --format "{{.ID}}: {{.Repository}}"

#以表格等距显示，并且有标题行
docker image ls --format "table {{.ID}}\t{{.Repository}}\t{{.Tag}}"



#查看镜像、容器、数据卷所占用的空间
docker system df

虚悬镜像(dangling image)
由于新旧镜像同名，旧镜像名称被取消，从而出现仓库名、标签均为 <none> 的镜像。
docker image ls -f dangling=true
# 删除虚悬镜像
docker image prune


docker image rm [选项] <镜像1> [<镜像2> ...]

docker commit [选项] <容器> [<镜像>[:<标签>]]
docker commit --author "Tao Wang"  --message "修改了默认网页" webserver  nginx:v2
docker diff <container>
docker history <镜像>[:<标签>]


vim Dockerfile

FROM debian:stretch

RUN buildDeps='gcc libc6-dev make wget' \
    && apt-get update \
    && apt-get install -y $buildDeps \
    && wget -O redis.tar.gz "http://download.redis.io/releases/redis-5.0.3.tar.gz" \
    && mkdir -p /usr/src/redis \
    && tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \
    && make -C /usr/src/redis \
    && make -C /usr/src/redis install \
    && rm -rf /var/lib/apt/lists/* \
    && rm redis.tar.gz \
    && rm -r /usr/src/redis \
    && apt-get purge -y --auto-remove $buildDeps

docker build  -t nginx:v3 .
docker build https://github.com/twang2218/gitlab-ce-zh.git#:11.1
docker build http://server/context.tar.gz
docker build - < Dockerfile
cat Dockerfile | docker build -
docker build - < context.tar.gz


COPY hom* /mydir/
COPY hom?.txt /mydir/
COPY --chown=<user>:<group> files* /mydir/

FROM scratch
ADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz /

CMD ["nginx", "-g", "daemon off;"]


FROM ubuntu:18.04
RUN apt-get update \
    && apt-get install -y curl \
    && rm -rf /var/lib/apt/lists/*
ENTRYPOINT [ "curl", "-s", "https://ip.cn" ]

ENV VERSION=1.0 DEBUG=on \
    NAME="Happy Feet"

ARG <参数名>[=<默认值>]

# 在运行时自动挂载为匿名卷，任何向 /data 中写入的信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。
VOLUME ["<路径1>", "<路径2>"...]
VOLUME /data

WORKDIR <工作目录路径>

EXPOSE <端口1> [<端口2>...]

USER <用户名>[:<用户组>]
RUN groupadd -r redis && useradd -r -g redis redis
USER redis

如果以 root 执行的脚本，在执行期间希望改变身份，比如希望以某个已经建立好的用户来运行某个服务进程，不要使用 su 或者 sudo，这些都需要比较麻烦的配置，而且在 TTY 缺失的环境下经常出错。建议使用 gosu。
# 建立 redis 用户，并使用 gosu 换另一个用户执行命令
RUN groupadd -r redis && useradd -r -g redis redis
# 下载 gosu
RUN wget -O /usr/local/bin/gosu "https://github.com/tianon/gosu/releases/download/1.7/gosu-amd64" \
    && chmod +x /usr/local/bin/gosu \
    && gosu nobody true
# 设置 CMD，并以另外的用户执行
CMD [ "exec", "gosu", "redis", "redis-server" ]


vscode 关闭标题栏
设置／窗口／Title Bar Style 设置 custom


开机等待时间
sudo gedit /etc/default/grub
#GRUB_TIMEOUT=1
GRUB_RECORDFAIL_TIMEOUT=1
sudo update-grub


dpkg --get-selections | grep firefox
sudo apt-get purge firefox firefox-*

sudo gedit /etc/sudoers
zbseoag ALL=(ALL) NOPASSWD: ALL
%admin ALL=(ALL) NOPASSWD: ALL

Dash to Panel

mount -t auto /dev/cdrom /mnt/cdrom
vi /etc/apt/sources.list



[rǒng yú]
冗余
[zǔ sè]  
阻塞
[kuàng jià]  
框架

1）sudo apt-get install open-vm-tools
2）sudo apt-get install open-vm-tools-desktop


在此处打开命令行

计算机\HKEY_CLASSES_ROOT\Directory\Background\shell\cmd
计算机\HKEY_CLASSES_ROOT\Directory\Background\shell\Powershell
就在刚才位置的下面。 ShowBasedOnVelocityId   重命名为 HideBasedOnVelocityId


"D:\Program Files\VMware Workstation\vmware-kvm.exe" –-preferences



npm config set registry https://registry.npm.taobao.org
npm config get registry

npm install express -g #全局安装
npm list -g

在当前目录下执行 npm link 就可以在代码中用require加载全局模块了

npm uninstall express
npm ls
npm update express
npm search express


#docker 安装
sudo apt-get remove docker docker-engine docker.io containerd runc
sudo apt-get update
sudo apt-get install   apt-transport-https     ca-certificates     curl     gnupg-agent     software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo apt-key fingerprint 0EBFCD88
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
sudo apt-get update
sudo apt-get install docker-ce docker-ce-cli containerd.io
sudo usermod -aG docker zbseoag

sudo mkdir -p /var/lib/mongo
sudo mkdir -p /var/log/mongodb
sudo chown zbseoag /var/lib/mongo     
sudo chown zbseoag /var/log/mongodb   

Run MongoDB.
To run MongoDB, run the mongod process at the system prompt.
mongod --dbpath /var/lib/mongo --logpath /var/log/mongodb/mongod.log --fork
mongo

http://localhost:27017/


redis-cli info | grep config 


dpkg -l |grep ^rc|awk '{print $2}' |sudo xargs dpkg -P              清除残余的配置文件

sudo apt-get install libtool  
sudo apt install autoreconf  


redis-cli> info replication

redis-server 6400.conf --sentinel &&  redis-server 6401.conf --sentinel

redis-cli --cluster create  172.18.0.2:6379 172.18.0.3:6379 172.18.0.4:6379 172.18.0.5:6379 172.18.0.6:6379 172.18.0.7:6379 --cluster-replicas 1


redis-cli -c -h 172.18.0.2 -p 6379

#查看主节点
redis-cli -h 172.18.0.2 cluster nodes | grep master

#主节点进入下线状态
redis-cli -h 172.18.0.2 debug segfault 

redis-cli -h 172.18.0.3 cluster nodes


redis-cli --cluster add-node 172.18.0.8:6379 172.18.0.2:6379 --cluster-slave --cluster-master-id e6d0ea4e0d07108ebecbcec5fecf91d7518dd64c


cluster addslots
cluster count-failure-reports
cluster countkeysinslot
cluster getkeysinslot
cluster delslots
cluster failover
cluster forget
cluster info
cluster keyslot
cluster meet
cluster nodes
cluster replicas <master-node-id> 
cluster replicate
cluster reset
cluster saveconfig
cluster set-config-epoch
cluster setslot
cluster slaves
cluster slots
readonly
readwrite


subscribe channle
unsubscribe channle

psubscribe channle
punsubscribe channle

publish channle message

multi
  incr foo
  incr bar
exec | discard


被 WATCH 的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在 EXEC 执行之前被修改了， 那么EXEC 返回nil-reply来表示事务已经失败。
WATCH mykey  key1  key2  key3
        val = GET mykey
        val = val + 1
MULTI
        SET mykey $val
EXEC  #不管事务是否成功执行， 对所有键的监视都会被取消。



data.txt:
SET Key0 Value0
SET Key1 Value1
...
SET KeyN ValueN

cat data.txt | redis-cli --pipe


redis-cli config set notify-keyspace-events KEA
redis-cli --csv psubscribe '__key*__:*' 
...
Reading messages... (press Ctrl-C to quit)


另一个
redis-cli
> set foo 123


sudo apt-get -y install socat logrotate init-system-helpers adduser

sudo apt-get install -y erlang-base \
  erlang-asn1 erlang-crypto erlang-eldap erlang-ftp erlang-inets \
  erlang-mnesia erlang-os-mon erlang-parsetools erlang-public-key \
  erlang-runtime-tools erlang-snmp erlang-ssl \
  erlang-syntax-tools erlang-tftp erlang-tools erlang-xmerl

sudo dpkg -i rabbitmq-server_3.8.3-1_all.deb


ps -ef  |grep rabbitmq

rabbitmq-server start
lsof -i:5672

rabbitmq-plugins enable rabbitmq_management
http://localhost:15672
guest : guest


docker run -d --rm --name dede  php:5.6.15-apache
docker cp dede:/usr/local/etc/php  /home/zbseoag/docker/volume/php56
docker cp dede:/usr/src/php/php.ini-development /home/zbseoag/docker/volume/php56/php
cd /home/zbseoag/docker/volume/php56/php && mv php.ini-development php.ini


docker run -d  --name dede \
-v /home/zbseoag/docker/volume/php56/apache2:/etc/apache2 \
-v /home/zbseoag/docker/volume/php56/php:/usr/local/etc/php \
-v /home/zbseoag/docker/volume/php56/www:/var/www/html \
php:5.6.15-apache




php -r "copy('https://getcomposer.org/installer', 'composer-setup.php');"
php -r "if (hash_file('sha384', 'composer-setup.php') === 'e0012edf3e80b6978849f5eff0d4b4e4c79ff1609dd1e613307e16318854d24ae64f26d17af3ef0bf7cfb710ca74755a') { echo 'Installer verified'; } else { echo 'Installer corrupt'; unlink('composer-setup.php'); } echo PHP_EOL;"
php composer-setup.php  --filename=composer
sudo mv  composer /usr/local/bin


用户向入口脚本 web/index.php 发起请求。
入口脚本加载应用配置并创建一个应用 实例去处理请求。
应用通过请求组件解析请求的 路由。
应用创建一个控制器实例去处理请求。
控制器创建一个动作实例并针对操作执行过滤器。
如果任何一个过滤器返回失败，则动作取消。
如果所有过滤器都通过，动作将被执行。
动作会加载一个数据模型，或许是来自数据库。
动作会渲染一个视图，把数据模型提供给它。
渲染结果返回给响应组件。
响应组件发送渲染结果给用户浏览器。


gem install jekyll
jekyll new myblog --force
cd myblog
jekyll serve [--detach]  [--no-watch][--watch][--drafts]


$ jekyll build [--drafts]
# => 当前文件夹中的内容将会生成到 ./_site 文件夹中。

# destination 文件夹会在站点建立时被清理，保留的文件和文件夹应在 <keep_files> 里指定
$ jekyll build --source <source> --destination <destination>
# => 指定源文件夹<source>中的内容将会生成到目标文件夹<destination>中。


├── _config.yml
├── _drafts
|   ├── begin-with-the-crazy-ideas.textile
|   └── on-simplicity-in-technology.markdown
├── _includes
|   ├── footer.html
|   └── header.html
├── _layouts
|   ├── default.html
|   └── post.html
├── _posts
|   ├── 2007-10-29-why-every-programmer-should-play-nethack.textile
|   └── 2009-04-26-barcamp-boston-4-roundup.textile
├── _site
├── .jekyll-metadata
└── index.html


默认模板
sudo gem install bundler
xdg-open $(bundle info --path minima)


---
layout: post
title: Blogging Like a Hacker
permalink: /other
published: false
---



http://dev.mysql.com/doc/index-other.html

http://dev.mysql.com/doc/sakila/en/sakila-installation.html


show global|session variables like 'vari_name'


show global variables like 'slow_query_log%';
show global variables like 'slow_query_log_file'
show global variables like 'log_queries_not_using_indexes';
show global variables like 'long_query_time';


set global slow_query_log = on;
set global slow_query_log_file = '/var/lib/mysql/aaa_slow_query.log';
set global long_query_time = 1;
set global log_queries_not_using_indexes = on;


重复索引检测
pt-duplicate-key-checker -h 127.0.0.1 -uroot -p '123456'


/usr/sbin/mysqld --verbose --help | grep -A  l 'Default options'


explain select max(payment_date) from payment;

create index idx_paydate on payment(payment_date);

select count(release_year='2006' or NULL) as '2006 year', count(release_year='2007' or NULL) as '2007 year' from film;

EXPLAIN	select actor.first_name, actor.last_name,count(*) from film_actor inner join actor using(actor_id) GROUP BY film_actor.actor_id;


在 MySQL 中，NULL 值与任何其它值的比较永远返回 NULL，即 NULL = NULL 返回 NULL。
MySQL 为 NULL 值处理提供了三大运算符: IS NULL、IS NOT NULL、<=>



mysql 加入自启动
chkconfig mysqld on
systemctl list-unit-files | grep mysql


# 查看端口
netstat -ln | grep 3306



OLTP，也叫联机事务处理（Online Transaction Processing）

OLAP，也叫联机分析处理（Online Analytical Processing）

#all onde
127.0.0.1:9200/_cat/nodes?
127.0.0.1:9200/_cluster/status



docker run -d --link elastic:elastic -p 5601:5601 --name kibana docker.elastic.co/kibana/kibana:7.6.2




工厂模式：通过工厂类或者方法去创建对象
单例模式：使某个类的对象仅允许创建一个。
注册模式：全局共享和交换对象。
适配器模式：将不同的函数接口封装成统一的标准
策略模式：
数据对象映射





php7
1、对函数的参数和返回值类型增加了限定。增加了类型之后，php的 jit（just in time 运行时，将指令转成二进制机器码） 可以准确判断变量类型，生成最佳机器指令。
function test(int $a, string $b):int{    }

2、错误异常，php7 可以使用 try/catch 捕获异常


一个 Elasticsearch 集群可以包含多个索引 > 类型 > 文档 > 属性

GET _search
{
  "query": {
    "match_all": {}
  }
}


GET _count
{
  "query": {
    "match_all": {}
  }
}



2.了解 PHP 的 Composer 包依赖管理机制，了解 PSR 代码规范与接口规范；

Composer 是一个 PHP 包依赖管理工具，先通过 composer.json 定义依赖的包，用命令下载这些依赖。然后开发者就可以引入包并使用了。
每当安装完依赖后，Composer 将把安装时确切的版本号列表写入 composer.lock 文件。这将锁定该项目的特定版本。



IO 多路复用是什么？有哪些 api？


select 和 epoll 的区别？水平触发和边缘触发的区别是啥？使用的时候需要注意什么？

epoll 储存描述符的数据结构是什么？
select 有描述符限制吗？是多少？

进程 / 线程 / 协程区别？go 和 swoole 的协程实现有啥区别？（分配资源的基本单位 / 运行和调度的基本单位 / 用户线程，M:N 模型和 N:1 模型）
PHP（php 源代码，主流 php 框架源代码）


描述一下 cli 模式下的几个生命周期？
模块初始化，请求初始化 ， 请求关闭




内存分配流程？为什么要这么设计？


GC 的出现是为了解决什么问题？什么时候会触发 GC？说下大概流程



php 里的数组是怎么实现的？（这里要注意下 php5 和 php7 实现的区别，优化了非常多）


nginx 和 php-fpm 的通信机制？fast-cgi 和 cgi 区别？

php-fpm 创建 worker 进程的规则是什么？不同场景下怎么选择？
php 和 mysql 的通信机制？长链接和短链接啥区别？怎么实现的？连接池要怎么实现？
swoole 协程的原理？（遇到阻塞时引发 php 栈和 c 栈的切换，细节可以参考下我的文章）
依赖注入是什么？如何实现的？能解决什么问题？（代码层面不再依赖具体实现，解耦）
mysql（高性能 mysql/mysql 技术内幕 innodb 储存引擎 / 数据库系统实现）
innodb 的索引组织方式？（聚簇索引必须要很清楚，注意 innodb 聚簇索引叶子结点保存的是完整数据，innodb 普通索引叶子保存的是记录的主键，myisam 索引叶子保存的是记录的位置 / 偏移量）
B + 树的结构和插入细节？为什么主键一般都要自增？和 B 树什么区别？为什么索引要使用 B + 树不是 B 树也不是其他的平衡树？为什么 redis 可以用跳表？（关键词：页的分裂，随机 IO，缓存体系）
常见的优化（这里我就不展开了，主要考察覆盖索引查询和最左匹配，其实只要清楚 innodb 索引的结构，这些都不需要记忆，自然而然推导出来的）
redolog/undolog/binlog 的区别？binlog 的几种格式？说下两阶段提交？
事务隔离级别和不同级别会出现的问题，innodb 默认哪个级别？MVCC 怎么实现的？快照读和当前读有啥区别？幻读的问题怎么解决？
死锁什么时候会出现？应用层应该怎么做避免死锁？mysql 是怎么处理死锁的呢？
int 占多少字节？bigint 呢？int (3) 和 int (11) 有区别吗？可以往 int (3) 里存 1 亿吗？varchar 最长多少？
sql 的执行流程（原始 sql-> 词法语法分析生成 AST-> 关系代数表达式（逻辑计划）-> 逻辑优化（谓词下推 / 常量传递）-> 物理查询优化（计算最佳 cost 路径，扫表还是使用索引，join 算法）-> 执行，仅做参考）
redis（redis 源代码）
sds 的结构是什么？为什么要存长度？跟 c 里的字符串有什么区别？（关键词：获取长度复杂度 O (1) 和 O (n)，二进制安全，保存 \0，跟 C 库字符串函数可以通用）
hash 怎么实现的？怎么解决 hash 冲突？除了 hashTable 还有别的吗？
zset 怎么实现的？跳表是怎么插入的？为什么选择跳表不用其他平衡二叉树？除了跳表还有别的吗？
rehash 过程？会主动 rehash 吗？
用 redis 可以实现队列吗？有什么优点和缺点？
用 redis 怎么实现一个延时队列？
rdb 和 aof 过程？rdb 为什么可以用创建子进程的方式进行？（这里考察一个 cow）这两种持久化方式会丢数据吗？
redis 为什么快？（主要考察一个 IO 多路复用和单线程不加锁）
一致性哈希是什么？节点较少时数据分布不均匀怎么办？
简单说下几种 key 的淘汰策略，redis 里的 lru 算法，什么时候会触发？实现细节是什么？怎么保证淘汰合理的 key？
lua 脚本的作用是什么？
缓存击穿 / 穿透 / 雪崩的处理策略
nginx
LVS 和 Nginx 分别作用在 osi 哪一层？
负载均衡算法
数据结构
布隆过滤器，什么时候用？优点是什么？



简介
Composer 是 PHP 的一个依赖管理工具。它允许你申明项目所依赖的代码库，并在项目中帮你自动安装这它们。

系统要求
PHP5.3.2 以上版本和一些 PHP 配置项，对于任何不兼容项，安装程序都会抛出警告。


依赖管理
它在每个项目的基础上进行管理，在你项目的某个目录中（例如 vendor）进行安装。默认情况下它不会在全局安装任何东西。
Composer 这样为你解决问题：你有一个项目依赖于若干个库，其中一些库依赖于其他库。你声明你所依赖的库，Composer 会帮你寻找并自动安装它们。


自动加载
除了库的下载，Composer 还准备了一个自动加载文件 vendor/autoload.php，它可以加载 Composer 下载的库中所有的类文件。
你可以在 composer.json 的 autoload 字段中增加自己的 autoloader。
{
    "autoload": {
        "psr-4": {"Acme\\": "src/"}
    }
}

composer.json ：项目安装
在项目中使用 Composer，你只需要一个 composer.json 文件。该文件包含了项目的依赖和其它的一些元数据。

require 声明依赖
{
    "require": {
        "包名称": "版本号"
    }
}

包版号
通配符 *
使用比较操作符指定有效的版本范围。多个范围用逗号隔开表示 AND，一个管道符号 | 将作为OR处理。AND 高于 OR。
使用 ~ 指定最低版本，但允许版本号的最后一位数字上升，如：~1.2.3 表示 >=1.2.3 且 <1.3，即：只有版本号最后一位可以上升。


注意：
将 vendor 添加到 .gitignore 文件中，防止提交到服务器。


composer.lock - 锁文件
在安装依赖后，Composer 会把安装时确切的版本号列表写入 composer.lock 文件，这将锁定该项目的特定版本。
请提交你应用程序的 composer.lock 到你的版本库中，因为 install 命令会检查锁文件是否存在，从而决定是否忽略 composer.json 文件去下载指定版本的依赖库。但对于库，并不一定建议提交锁文件。

Packagist
Packagist 是 Composer 的主要资源库。 一个 Composer 的库基本上是一个包的源：记录了可以得到包的地方。

composer init

php composer.phar install

php composer.phar update

如果只想安装或更新一个依赖，你可以白名单它们：
php composer.phar update monolog/monolog [...]

除了 PSR-4 自动加载，classmap 也是支持的。


composer config --list -g
composer config -g notify-on-install false

引用本地自定义的包只更新加载器
composer dump-autoload


"autoload": {

  "classmap": ["othsrc/","classsrc.php"],

  "files": ["othsrc/filesrc.php"],

  "psr-4": {"Foo\Bar\": "src"} 
}



全局配置
所有项目都会使用该镜像地址：
composer config -g repo.packagist composer https://mirrors.aliyun.com/composer/
取消配置
composer config -g --unset repos.packagist

调试
composer -vvv require alibabacloud/sdk

1. 建议先将Composer版本升级到最新：
composer self-update
2. 执行诊断命令：
composer diagnose
3. 清除缓存：
composer clear
4. 若项目之前已通过其他源安装，则需要更新 composer.lock 文件，执行命令：
composer update --lock

平台软件包
Composer 将那些已经安装在系统上，但并不是由 Composer 安装的包视为一个虚拟的平台软件包。包括PHP本身，PHP扩展和一些系统库。

composer show --platform 命令来获取可用的平台软件包的列表。




为什么需要重视命名？
好的命名即是注释，别人一看到你的命名就知道你的变量、方法或者类是做什么的！ 好的命名对于其他人（包括你自己）理解你的代码有着很大的帮助！
好的代码本身就是注释，我们要尽量规范和美化自己的代码来减少不必要的注释。若编程语言足够有表达力，就不需要注释，尽量通过代码来阐述。

常见命名规则以及适用场景

驼峰命名法（CamelCase）：驼峰命名法应该我们最常见的一个，这种命名方式使用大小写混合的格式来区别各个单词，并且单词之间不使用空格隔开或者连接字符连接的命名方式。
大驼峰命名法（UpperCamelCase）类名需要使用大驼峰命名法
小驼峰命名法（lowerCamelCase）方法名、参数名、成员变量、局部变量需要使用小驼峰命名法。

蛇形命名法（snake_case）：各个单词之间通过下划线连接，使用场景是命名所需要的单词比较多的时候。测试方法名、常量、枚举名称需要使用蛇形命名法
串式命名法（kebab-case）：各个单词之间通过中横杠连接，建议项目文件夹名称使用串式命名法。

Codelf:变量命名神器：https://unbug.github.io/codelf/



linux 命令

compgen -c 将列出你可以运行的所有命令。
compgen -a 将列出你可以运行的所有别名。
compgen -b 将列出你可以运行的所有 built-ins 。
compgen -k 将列出你可以运行的所有关键字。
compgen -A function 将列出你可以运行的所有函数。
compgen -A function -abck 将逐一列出上所有内容。





单点登录 Single /sing guo/ Sign /sai in/ On，简称就是SSO。在多个应用系统中，只需要登录一次，就可以访问其他相互信任的应用系统。


同域下的单点登录: cookie 的域设置在同一级的域名下,再解决session 共享问题.

不同域下的单点登录:

CAS 是 Central Authentication Service的缩写，中央认证服务，一种独立开放指令协议, 旨在为 Web 应用系统提供一种可靠的单点登录方法。

1.用户访问app系统，app系统是需要登录的，但用户现在没有登录。
2.跳转到 CAS 服务器，即 SSO登录系统， SSO系统也没有登录，弹出用户登录页。
3.用户填写用户名、密码，SSO系统进行认证后，将登录状态写入 SSO 的 session，浏览器中写入 SSO 域下的 Cookie。
4.SSO系统登录完成后会生成一个ST（Service Ticket），然后跳转到app系统，同时将ST作为参数传递给app系统。
5.app系统拿到 ST 后，从后台向 SSO 发送请求，验证ST是否有效。
6.验证通过后，app系统将登录状态写入 session 并设置 app 域下的 Cookie。


访问app2系统时的流程。

1.用户访问app2系统，app2系统没有登录，跳转到SSO。
2.由于 SSO 已经登录了，不需要重新登录认证。
3.SSO生成ST，浏览器跳转到app2系统，并将ST作为参数传递给app2。
4. app2拿到ST，后台访问SSO，验证ST是否有效。
5.验证成功后，app2将登录状态写入session，并在app2域下写入Cookie。

这样，app2系统不需要走登录流程，就已经是登录了。CAS 方式，app 和 app2在不同的域，它们之间不共享 session 也是没问题的。

总结
1.单点登录（SSO系统）是保障各业务系统的用户资源的安全 。
2.各个业务系统获得的信息是，这个用户能不能访问我的资源。
3.单点登录，资源都在各个业务系统这边，不在SSO那一方。 
4.用户在给SSO服务器提供了用户名密码后，作为业务系统并不知道这件事。SSO随便给业务系统一个ST，那么业务系统是不能确定这个ST是用户伪造的，还是真的有效，所以要拿着这个ST去SSO服务器再问一下，这个用户给我的ST是否有效，是有效的我才能让这个用户访问。




OAuth 是 Open Authority /wo fo ti/ 的缩写，这两者都是使用令牌的方式来代替用户密码访问应用。

上面的流程大概为：

用户输入网址进入业务系统Protected App，系统发现用户未登录，将用户重定向到单点登录系统CAS Server，并带上自身地址service参数
用户浏览器重定向到单点登录系统，系统检查该用户是否登录，这是SSO(这里是CAS)系统的第一个接口，该接口如果用户未登录，则将用户重定向到登录界面，如果已登录，则设置全局session，并重定向到业务系统
用户填写密码后提交登录，注意此时的登录界面是SSO系统提供的，只有SSO系统保存了用户的密码，
SSO系统验证密码是否正确，若正确则重定向到业务系统，并带上SSO系统的签发的ticket
浏览器重定向到业务系统的登录接口，这个登录接口是不需要密码的，而是带上SSO的ticket，业务系统拿着ticket请求SSO系统，获取用户信息。并设置局部session，表示登录成功返回给浏览器sessionId(tomcat中叫JSESSIONID)
之后所有的交互用sessionId与业务系统交互即可
OAuth2.0
OAuth2.0有多种模式，这里讲的是OAuth2.0授权码模式，OAuth2.0的流程跟SSO差不多

用户在某网站上点击使用微信授权，这里的某网站就类似业务系统，微信授权服务器就类似单点登录系统
之后微信授权服务器返回一个确认授权页面，类似登录界面，这个页面当然是微信的而不是业务系统的
用户确认授权，类似填写了账号和密码，提交后微信鉴权并返回一个ticket，并重定向业务系统。
业务系统带上ticket访问微信服务器，微信服务器返回正式的token，业务系统就可以使用token获取用户信息了


translate /chuan si lei te/


子shell是嵌在圆括号()内部的命令序列，子Shell内部定义的变量为局部变量。

COMMAND1
COMMAND2
(
  IFS=:
  PATH=/bin
  unset TERMINFO
  set -C
  shift 5
  COMMAND-3
  COMMAND-4
  exit 3 # 只是从子shell退出。
)
# 父shell不受影响，变量值没有更改。
COMMAND5




并发：指多个事件在同一段时间内进行。多道程序环境下，虽然程序只能是分时地交替执行，但从宏观来看，在一段时间内有多个程序在同时运行。
并行：指多个事件在同一时间点进行。在多道程序环境下，并行性使多个程序同一时刻可在不同 CPU 上同时执行。

串行：多个任务按顺序一个一个执行。
并行：多个任务同时执行，异步是多个任务并行的前提条件。

同步：等待同步结果返回，才能继续往下执行。
异步：不必等待返回结果，接着往下执行。实现异步可以采用多线程技术或则交给另外的进程来处理。


它通过强制事务排序，使之不可能相互冲突

shutdown [/i 显示对话框 | /l 立即注销 | /s 关机 | /r 重启 | /a 中止关机 | /p 本地计算机 | /h 休眠 | /e 记录意外关闭 ] [/f 强制退出应用程序 ] [/m \\<ComputerName>] [/t <XXX>] [/d 原因 [p 计划 | u: 用户定义] <XX 主原因号，小于256的正整数>:<YY 次原因号，小于65536的正整数 > [/c comment 注释 ]]


start [<Title 标题>] [/d <Path 启动目录>] [/i 传递启动环境 ] [{/min 最小化 | /max 最大化 }] [{/separate | /shared}] [ 优先级 {/low | /normal | /high | /realtime | /abovenormal | belownormal } ] [/affinity <HexAffinity>] [/wait 等待结束 ] [/elevate 以管理身份] [/b 在当前命令行，CTRL + BREAK 中断]  [ <Program 程序>  [<Parameter 程序运行参数>... ] ]




docker volume create portainer_data
docker run --network=host --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data -d portainer/portainer


docker run --name=test1 --privileged -v /usr/bin/docker:/usr/bin/docker -v /var/run/docker.sock:/var/run/docker.sock -v etc:/etc -d nginx:1.9
run --network=host --privileged -v /usr/bin/docker:/usr/bin/docker -v /var/run/docker.sock:/var/run/docker.sock -v etc:/etc -d test nginx:1.9


docker run --network=host -v etc:/etc -v /e:/e -w /e -dit --name=php php:7.3-fpm bash

docker cp test:/etc/mysql /etc/mysql

docker run --rm -it --name=test -e MYSQL_ROOT_PASSWORD=123456 -d mysql:8.0


docker run --network=host --name mysql -v database:/var/lib/mysql -v /etc/mysql:/etc/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:8.0

docker run --network=host --name mysql  -e MYSQL_ROOT_PASSWORD=123456 -d mysql:8.0

2，输入以下语句，进入mysql库：

use mysql
SHOW VARIABLES LIKE 'validate_password%';
SET global validate_password.policy = LOW;
SET global validate_password.length = 6;
ALTER USER 'root'@'localhost' IDENTIFIED BY '123456';
ALTER USER 'root'@'%' IDENTIFIED BY '123456';
update user set host='%' where user ='root' limit 1;
select host,user,plugin from user;
update user set plugin='mysql_native_password' where user='root';
FLUSH PRIVILEGES;
GRANT ALL PRIVILEGES ON *.* TO 'root'@'%'WITH GRANT OPTION;



JAVA_TOOL_OPTIONS -Dfile.encoding=UTF-8







rabbitmqctl 服务管理
rabbitmq-diagnostics 诊断和健康检查
rabbitmq-plugins 插件管理
rabbitmq 维护任务队列
rabbitmq-upgrade 升级维护

INSERT INTO `chanyin.luxecome.com`.`app_version` (`app_version_id`, `app_version_os`, `app_version_code`, `app_version_name`, `app_version_content`, `app_version_is_force`, `app_version_download_url`, `app_version_create_time`, `app_version_update_time`) VALUES (42, 'android', 17, '1.9', '升级美颜、弹幕等，请下载更新', 'N', 'https://a.app.qq.com/o/simple.jsp?pkgname=com.hotniao.live.chanyin', 1610682677, 1610683011);



sudo apt install -y \
   autoconf \
   dpkg-dev \
   file \
   g++ \
   gcc \
   libc6-dev \
   make \
   pkg-config \
   re2c \
   ca-certificates \
   curl \
   xz-utils \
   libargon2-dev \
   libcurl4-openssl-dev \
   libedit-dev \
   libonig-dev \
   libsodium-dev \
   libsqlite3-dev \
   libssl-dev \
   libxml2-dev \
   zlib1g-dev \
   libfreetype6-dev \
   libjpeg-turbo8-dev \
   libpng-dev \
   libzip-dev \



./configure --prefix=/d/usr/nginx \
 --user=zbseoag \
 --group=zbseoag \
 --with-select_module \
 --without-select_module \
 --with-poll_module \
 --without-poll_module \
 --with-threads \
 --with-file-aio \
 --with-http_ssl_module \
 --with-http_v2_module \
 --with-http_realip_module \
 --with-http_addition_module \
 --with-http_xslt_module \
 --with-http_xslt_module=dynamic \
 --with-http_image_filter_module \
 --with-http_image_filter_module=dynamic \
 --with-http_sub_module \
 --with-http_dav_module \
 --with-http_flv_module \
 --with-http_mp4_module \
 --with-http_gunzip_module \
 --with-http_gzip_static_module \
 --with-http_auth_request_module \
 --with-http_random_index_module \
 --with-http_secure_link_module \
 --with-http_degradation_module \
 --with-http_slice_module \
 --with-http_stub_status_module \
 --with-http_perl_module \
 --with-http_perl_module=dynamic \
 --with-mail \
 --with-mail=dynamic \
 --with-mail_ssl_module \
 --with-stream \
 --with-stream=dynamic \
 --with-stream_ssl_module \
 --with-stream_realip_module \
 --with-stream_ssl_preread_module \
 --with-compat \
 --with-pcre \
 --with-pcre-jit \
 --with-libatomic \
 --with-debug 


docker run --network=network --restart=on-failure:1 -d --name=mysql -e MYSQL_ROOT_PASSWORD=123456 -p 3306:3306  mysql:5.6
docker run --network=network --restart=on-failure:1 -d --name=redis -p 6379:6379  redis:6.0
docker run --network=network --restart=on-failure:1 -d --name php7 -w /e -v /e:/e -p 9000:9000 php:7.3-fpm

HKEY_CURRENT_USER\Software\Microsoft\Windows\CurrentVersion\Explorer\Discardable\PostSetup\ShellNew\Classes

sed -i "s/deb.debian.org/mirrors.aliyun.com/g" /etc/apt/sources.list && apt update && apt upgrade -y


php docker 安装插件
sed -i "s/deb./mirrors.aliyun.com/g" /etc/apt/sources.list && apt update
apt install -y libwebp-dev libjpeg-dev libpng-dev libfreetype6-dev libzip-dev libzstd-dev
docker-php-ext-configure gd --with-webp-dir --with-jpeg-dir --with-png-dir --with-freetype-dir
docker-php-ext-install gd pdo pdo_mysql zip

pecl install psr
pecl install phalcon


php think addon -a mydemo -c create


FROM ubuntu
ADD sources.list /etc/apt/
ADD run.sh /home/
RUN apt-get clean && apt-get update
RUN apt-get -y install mysql-server
RUN chmod +x /home/run.sh
EXPOSE 3306 
CMD ["/home/run.sh"]


win10专业版用户请依次输入：
slmgr /ipk W269N-WFGWX-YVC9B-4J6C9-T83GX
slmgr /skms kms.03k.org
slmgr /ato


win7 
slmgr /ipk 342DG-6YJR8-X92GV-V7DCV-P4K27 && slmgr /skms kms.03k.org && slmgr /ato


kms.03k.org
kms.chinancce.com
kms.lotro.cc
cy2617.jios.org
kms.shuax.com
kms.luody.info
kms.cangshui.net
zh.us.to
kms.library.hk
xykz.f3322.org
kms.binye.xyz
kms.tttal.com
kms.v0v.bid
kms.moeclub.org
amrice.top
kms.digiboy.ir
kms.lolico.moe
kms8.MSGuides.com
kms9.MSGuides.com

svn
zhengbaoshan hn7812


docker run --name=php --network=host -v /d/etc/php:/usr/local/etc  -v /d:/d -v /e:/e -d php:7.3-fpm

docker run --name=nginx --network=host -v /d/etc/nginx:/etc/nginx -v /d:/d -v /e:/e -d nginx


docker run --network=host --name mysql  -v /d/etc/mysql:/etc/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:8

docker run --network=host --name mysql  -e MYSQL_ROOT_PASSWORD=123456 -d mysql:8.0

use mysql;
update user set plugin='mysql_native_password' where  user='root';

php-fpm:
usermod -u 1000 www-data
groupmod -g 1000 www-data


mysql_secure_installation

[mysqld]
default_authentication_plugin = mysql_native_password

use mysql;
SELECT Host, User, plugin from user;
ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY '123456';
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '123456';
FLUSH PRIVILEGES;
SELECT Host, User, plugin from user;

^(\n|;)(\s|;)+.*\n


docker build -f Dockerfile.php7.3 -t zbseoag/php:7.3 .

INSERT INTO `chanyin.luxecome.com`.`app_version` (`app_version_id`, `app_version_os`, `app_version_code`, `app_version_name`, `app_version_content`, `app_version_is_force`, `app_version_download_url`, `app_version_create_time`, `app_version_update_time`) VALUES (43, 'android', 17, '1.9', '发现新版本，请点击更新', 'N', 'https://a.app.qq.com/o/simple.jsp?pkgname=com.hotniao.live.chanyin', 1610765540, 1611136400);



zkServer.sh start
zkCli.sh
ls /
create /node value
get /node
set /node value2
delete /node

zkServer.sh start /d/etc/zookeeper/zoo1.cfg
zkServer.sh start /d/etc/zookeeper/zoo2.cfg
zkServer.sh start /d/etc/zookeeper/zoo3.cfg

zkCli.sh -server 127.0.0.1:2181


sudo add-apt-repository ppa:ondrej/php
sudo apt-get update
sudo apt install php7.2-dev
sudo apt install php7.4-dev


sudo service mysql stop
sudo usermod -d /var/lib/mysql/ mysql
sudo service mysql start


ipconfig /flushdns


redis> CONFIG GET appendonly           # appendonly 处于关闭状态
redis> CONFIG SET appendonly yes       # 打开 appendonly
redis> CONFIG REWRITE                  # 将 appendonly 的修改写入到 redis.conf 中



runkit7_function_remove 


./ext_skel.php --ext myfunctions --std
cd myfunctions/
phpize
./configure
make




语法:	events { ... }
默认值:	—
上下文:	main
提供配置上下文，以解析那些影响连接处理的指令。

语法:	include file | mask;
默认值:	—
上下文:	任意


语法:	accept_mutex on | off;
默认值:	accept_mutex on;
上下文:	events
功能:   串行方式接入新连接。

语法:	accept_mutex_delay time;
默认值:	accept_mutex_delay 500ms;
上下文:	events

语法:	daemon on | off;
默认值:	daemon on;
上下文:	main
功能:   决定nginx是否应以守护进程的方式工作。


语法:	debug_connection address | CIDR | unix:;
默认值:	—
上下文:	events
开启针对特定客户端连接的调试日志。除开这些连接，其它连接将使用error_log指令设置的日志级别。

语法:	debug_points abort | stop;
默认值:	—
上下文:	main
这条指令用于调试。

语法:	error_log file | stderr [debug | info | notice | warn | error | crit | alert | emerg];
默认值:	
error_log logs/error.log error;
上下文:	main, http, server, location

语法:	env variable[=value];
默认值:	
env TZ;
上下文:	main

语法:	lock_file file;
默认值:	lock_file logs/nginx.lock;
上下文:	main


语法:	master_process on | off;
默认值:	master_process on;
上下文:	main
是否启动工作进程。


语法:	multi_accept on | off;
默认值:	multi_accept off;
上下文:	events
是否批量连接所有请求

语法:	pcre_jit on | off;
默认值:	
pcre_jit off;
上下文:	main
正则表达式使用“即时编译”(PCRE JIT)技术。

语法:	pid file;
默认值:	pid nginx.pid;
上下文:	main
定义存储nginx主进程ID的file。

语法:	ssl_engine device;
默认值:	—
上下文:	main
定义SSL硬件加速器的名字

语法:	timer_resolution interval;
默认值:	—
上下文:	main
在工作进程中降低定时器的精度，因此可以减少产生gettimeofday()系统调用的次数。

语法:	use method;
默认值:	—
上下文:	events
指定使用的连接处理method(方式)。 通常不需要明确设置，因为nginx默认会使用最高效的方法。

语法:	user user [group];
默认值:	user nobody nobody;
上下文:	main
定义工作进程使用的user和group身份。 如果省略group，nginx会使用与user相同的组名。

语法:	worker_aio_requests number;
默认值:	worker_aio_requests 32;
上下文:	events
在使用epoll连接处理方式的情况下使用aio时， 可以设置单个工作进程未处理的异步I/O操作的最大number(数量)。

语法:	worker_connections number;
默认值:	
worker_connections 512;
上下文:	events
每个工作进程可以打开的最大并发连接数实际的并发连接数是不能超过打开文件的最大数量限制的，这个限制可以用 worker_rlimit_nofile 指令修改。


语法:	worker_cpu_affinity cpumask ...;
默认值:	—
上下文:	main
绑定工作进程到指定的CPU集合。每个CPU集合使用一个标记允许使用的CPU的位图来表示。 需要为每个工作进程分别设置CPU集合。 工作进程默认不会绑定到任何特定的CPU。

比如
worker_processes    4;
worker_cpu_affinity 0001 0010 0100 1000;
将每个工作进程分别绑定至不同的CPU

worker_processes    2;
worker_cpu_affinity 0101 1010;
将第一个工作进程绑定至CPU0/CPU2，将第二个工作进程绑定至CPU1/CPU3


语法:	worker_priority number;
默认值:	worker_priority 0;
上下文:	main
定义工作进程的调度优先级。这与nice命令行所做的相同： number为负数代表优先级更高。通常允许的范围是[-20, 20]。

语法:	worker_processes number | auto;
默认值:	worker_processes 1;
上下文:	main
定义工作进程的数量。

语法:	worker_rlimit_core size;
默认值:	—
上下文:	main
修改工作进程的core文件尺寸的最大值限制(RLIMIT_CORE)，用于在不重启主进程的情况下增大该限制。


语法:	worker_rlimit_nofile number;
默认值:	—
上下文:	main
修改工作进程的打开文件数的最大值限制(RLIMIT_NOFILE)，用于在不重启主进程的情况下增大该限制。

语法:	worker_rlimit_sigpending number;
默认值:	—
上下文:	main
在支持rtsig连接处理方式的系统中，修改工作进程的信号队列长度限制(RLIMIT_SIGPENDING)，用于在不重启主进程的情况下增大该限制。

语法:	working_directory directory;
默认值:	—
上下文:	main
定义工作进程的当前工作路径。 主要用于设置core文件的目标地址。工作进程应当具有指定路径的写权限。


语法:	access_log path [format [buffer=size]];
        access_log off;
默认值:	access_log logs/access.log combined;
上下文:	http, server, location, if in location, limit_except


语法:	log_format name string ...;
默认值:	
log_format combined "...";
上下文:	http
指定日志的格式。

$body_bytes_sent发送给客户端的字节数，不包括响应头的大小； 该变量与Apache模块mod_log_config里的“%B”参数兼容。
$bytes_sent发送给客户端的总字节数。
$connection连接的序列号。
$connection_requests当前通过一个连接获得的请求数量。
$msec日志写入时间。单位为秒，精度是毫秒。
$pipe如果请求是通过HTTP流水线(pipelined)发送，pipe值为“p”，否则为“.”。
$request_length请求的长度（包括请求行，请求头和请求正文）。
$request_time请求处理时间，单位为秒，精度毫秒； 从读入客户端的第一个字节开始，直到把最后一个字符发送给客户端后进行日志写入为止。
$status响应状态。
$time_iso8601 ISO8601标准格式下的本地时间。
$time_local通用日志格式下的本地时间。
发送给客户端的响应头拥有“sent_http_”前缀。 比如$sent_http_content_range。

语法:	open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time];
        open_log_file_cache off;
默认值:	open_log_file_cache off;
上下文:	http, server, location
定义一个缓存，用来存储频繁使用的文件名中包含变量的日志文件描述符。 该指令包含以下参数：

max设置缓存中描述符的最大数量；如果缓存被占满，最近最少使用（LRU）的描述符将被关闭。
inactive设置缓存文件描述符在多长时间内没有被访问就关闭； 默认为10秒。
min_uses设置在inactive参数指定的时间里， 最少访问多少次才能使文件描述符保留在缓存中；默认为1。
valid设置一段用于检查超时后文件是否仍以同样名字存在的时间； 默认为60秒。

open_log_file_cache max=1000 inactive=20s valid=1m min_uses=2;



语法:	add_before_body uri;
默认值:	—
上下文:	location
在回复正文之前加入一段文字，nginx会发起一个子请求去获取这些文字。

语法:	add_after_body uri;
默认值:	—
上下文:	location
在回复正文之后加入一段文字，nginx会发起一个子请求去获取这些文字。

语法:	addition_types mime-type ...;
默认值:	addition_types text/html;
上下文:	http, server, location
指定生效的回复MIME类型，默认始终包含“text/html”。 如果设置类型为“*”，就会匹配任何类型


syntax:	add_header name value;
default:	—
context:	http, server, location


syntax:	expires [modified] time;
        expires epoch | max | off;
default:	expires off;
context:	http, server, location


语法:	aio on | off | sendfile;
默认值:	
aio off;
上下文:	http, server, location

location /video/ {
    sendfile       on;
    tcp_nopush     on;
    aio            sendfile;
}

语法:	alias path;
默认值:	—
上下文:	location
定义指定路径的替换路径
location ~ ^/users/(.+\.(?:gif|jpe?g|png))$ {
    alias /data/w3/images/$1;
}


语法:	chunked_transfer_encoding on | off;
默认值:	chunked_transfer_encoding on;
上下文:	http, server, location
允许关闭HTTP/1.1中的分块传输编码。在客户端软件不支持分块传输编码的时候，这条指令才有用。

语法:	client_body_buffer_size size;
默认值:	client_body_buffer_size 8k|16k;
上下文:	http, server, location
设置读取客户端请求正文的缓冲容量。如果请求正文大于缓冲容量，整个正文或者正文的一部分将写入临时文件。


语法:	client_body_in_file_only on | clean | off;
默认值:	client_body_in_file_only off;
上下文:	http, server, location
决定nginx是否将客户端请求正文整个写入文件。这条指令在调试时，或者使用$request_body_file变量时， 或者使用ngx_http_perl_module模块的 $r->request_body_file方法时都可以使用。


语法:	client_body_in_single_buffer on | off;
默认值:	client_body_in_single_buffer off;
上下文:	http, server, location
决定nginx将整个客户端请求正文保存在一块缓冲中。 这条指令推荐在使用$request_body变量时使用，可以节省引入的拷贝操作。

语法:	client_body_temp_path path [level1 [level2 [level3]]];
默认值:	client_body_temp_path client_body_temp;
上下文:	http, server, location
定义存储客户端请求正文的临时文件的目录。 支持在指定目录下多达3层的子目录结构。


语法:	client_body_timeout time;
默认值:	client_body_timeout 60s;
上下文:	http, server, location
定义读取客户端请求正文的超时。超时是指相邻两次读操作之间的最大时间间隔


语法:	client_header_buffer_size size;
默认值:	client_header_buffer_size 1k;
上下文:	http, server
设置读取客户端请求头部的缓冲容量。 对于大多数请求，1K的缓冲足矣。


语法:	client_header_timeout time;
默认值:	client_header_timeout 60s;
上下文:	http, server
定义读取客户端请求头部的超时。

语法:	client_max_body_size size;
默认值:	client_max_body_size 1m;
上下文:	http, server, location
设置允许客户端请求正文的最大长度。请求的长度由“Content-Length”请求头指定。

语法:	connection_pool_size size;
默认值:	
connection_pool_size 256;
上下文:	http, server
允许微调为每个连接分配的内存。这条指令对nginx的性能影响非常小，一般不应该使用。

语法:	default_type mime-type;
默认值:	
default_type text/plain;
上下文:	http, server, location
定义响应的默认MIME类型。


语法:	directio size | off;
默认值:	directio off;
上下文:	http, server, location
当读入长度大于等于指定size的文件时，开启DirectIO功能。

语法:	directio_alignment size;
默认值:	directio_alignment 512;
上下文:	http, server, location
为directio设置文件偏移量对齐。大多数情况下，按512字节对齐足矣， 但在Linux系统下使用XFS，需要将值扩大到4K。

语法:	disable_symlinks off;
disable_symlinks on | if_not_owner [from=part];
默认值:	
disable_symlinks off;
上下文:	http, server, location
决定nginx打开文件时如何处理符号链接
off
默认行为，允许路径中出现符号链接，不做检查。
on
如果文件路径中任何组成部分中含有符号链接，拒绝访问该文件。
if_not_owner
如果文件路径中任何组成部分中含有符号链接，且符号链接和链接目标的所有者不同，拒绝访问该文件。
from=part
当nginx进行符号链接检查时(参数on和参数if_not_owner)，路径中所有部分默认都会被检查。 而使用from=part参数可以避免对路径开始部分进行符号链接检查，而只检查后面的部分路径。 如果某路径不是以指定值开始，整个路径将被检查，就如同没有指定这个参数一样。 如果某路径与指定值完全匹配，将不做检查。 这个参数的值可以包含变量。


语法:	error_page code ... [=[response]] uri;
默认值:	—
上下文:	http, server, location, if in location
为指令错误定义显示的URI。当前配置级别没有error_page指令时，将从上层配置继承。 uri可以包含变量。

比如：

error_page 404             /404.html;
error_page 500 502 503 504 /50x.html;
而且，可以使用“=response语法改变响应状态码。比如：

error_page 404 =200 /empty.gif;
如果URI将被发送到一个被代理的服务器处理，或者发送到一个FastCGI服务器处理， 这些后端服务器又返回了不同的响应状态码（比如200、302、401或404），那么这些返回的状态码也可以由本指令处理：

error_page 404 = /404.php;
当然，也可以使用本指令对错误处理进行重定向：

error_page 403      http://example.com/forbidden.html;
error_page 404 =301 http://example.com/notfound.html;
对于例子中的第一行，nginx将向客户端发送302响应状态码。这种用法能使用的状态码只有301、302、303和307。

如果内部跳转时无需改变URI，可以将错误处理转到一个命名路径：

location / {
    error_page 404 = @fallback;
}

location @fallback {
    proxy_pass http://backend;
}
如果处理uri产生了错误，那么nginx将最后一次出错的HTTP响应状态码返回给客户端。


语法:	etag on | off;
默认值:	etag on;
上下文:	http, server, location
开启或关闭为静态文件自动计算 ETag 响应头。



语法:	if_modified_since off | exact | before;
默认值:	if_modified_since exact;
上下文:	http, server, location

指定响应的修改时间和“If-Modified-Since”请求头的比较方法：
off忽略“If-Modified-Since”请求头(0.7.34)；
exact精确匹配
before响应的修改时间小于等于“If-Modified-Since”请求头指定的时间。


语法:	ignore_invalid_headers on | off;
默认值:	ignore_invalid_headers on;
上下文:	http, server
控制是否忽略非法的请求头字段名。 合法的名字是由英文字母、数字和连字符组成，当然也可以包含下划线(由underscores_in_headers指令控制)。
本指令可以在默认虚拟主机的server配置层级中定义一次，那么这个值在监听在相同地址和端口的所有虚拟主机上都生效。

语法:	internal;
默认值:	—
上下文:	location
指定一个路径是否只能用于内部访问

语法:	keepalive_disable none | browser ...;
默认值:	
keepalive_disable msie6;
上下文:	http, server, location
针对行为异常的浏览器关闭长连接功能。 browser参数指定那些浏览器会受到影响。 值为msie6表示在遇到POST请求时，关闭与老版MSIE浏览器建立长连接。 值为safari表示在遇到Mac OS X和类Mac OS X操作系统下的Safari浏览器和类Safari浏览器时，不与浏览器建立长连接。 值为none表示为所有浏览器开启长连接功能。



语法:	keepalive_requests number;
默认值:	keepalive_requests 100;
上下文:	http, server, location
设置通过一个长连接可以处理的最大请求数。 请求数超过此值，长连接将关闭。


语法:	keepalive_timeout timeout [header_timeout];
默认值:	keepalive_timeout 75s;
上下文:	http, server, location
第一个参数设置客户端的长连接在服务器端保持的最长时间（在此时间客户端未发起新请求，则长连接关闭）。

语法:	large_client_header_buffers number size;
默认值:	large_client_header_buffers 4 8k;
上下文:	http, server
设置读取客户端请求超大请求的缓冲最大number(数量)和每块缓冲的size(容量)。 HTTP请求行的长度不能超过一块缓冲的容量，否则nginx返回错误414 (Request-URI Too Large)到客户端。 每个请求头的长度也不能超过一块缓冲的容量，否则nginx返回错误400 (Bad Request)到客户端。 缓冲仅在必需是才分配，默认每块的容量是8K字节。 即使nginx处理完请求后与客户端保持入长连接，nginx也会释放这些缓冲。


语法:	limit_except method ... { ... }
默认值:	—
上下文:	location
允许按请求的HTTP方法限制对某路径的请求。method用于指定不由这些限制条件进行过滤的HTTP方法，可选值有 GET、 HEAD、 POST、 PUT、 DELETE、 MKCOL、 COPY、 MOVE、 OPTIONS、 PROPFIND、 PROPPATCH、 LOCK、 UNLOCK 或者 PATCH。 指定method为GET方法的同时，nginx会自动添加HEAD方法。 那么其他HTTP方法的请求就会由指令引导的配置块中的ngx_http_access_module 模块和ngx_http_auth_basic_module模块的指令来限制访问。如：

limit_except GET {
    allow 192.168.1.0/32;
    deny  all;
}
请留意上面的例子将对除GET和HEAD方法以外的所有HTTP方法的请求进行访问限制。

语法:	limit_rate rate;
默认值:	limit_rate 0;
上下文:	http, server, location, if in location
限制向客户端传送响应的速率限制。参数rate的单位是字节/秒，设置为0将关闭限速。

语法:	limit_rate_after size;
默认值:	limit_rate_after 0;
上下文:	http, server, location, if in location
设置不限速传输的响应大小。当传输量大于此值时，超出部分将限速传送。


语法:	lingering_close off | on | always;
默认值:	lingering_close on;
上下文:	http, server, location
控制nginx如何关闭客户端连接。
默认值“on”指示nginx在完成关闭连接前等待和 处理客户端发来的额外数据。但只有在预测客户端可能发送更多数据的情况才会做此处理。
“always”指示nginx无条件等待和处理客户端的额外数据。
“off”指示nginx立即关闭连接，而绝不等待客户端传送额外数据。 这样做破坏了协议，所以正常条件下不应使用。


语法:	lingering_time time;
默认值:	lingering_time 30s;
上下文:	http, server, location
lingering_close生效时，这条指令定义nginx处理(读取但忽略)客户端额外数据的最长时间。 超过这段时间后，nginx将关闭连接，不论是否还有更多数据待处理。

语法:	lingering_timeout time;
默认值:	lingering_timeout 5s;
上下文:	http, server, location
lingering_close生效时，这条指令定义nginx等待客户端更多数据到来的最长时间。 

语法:	listen address[:port] [default_server] [setfib=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [ssl] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];
listen port [default_server] [setfib=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [ssl] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];
listen unix:path [default_server] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ssl] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];
默认值:	listen *:80 | *:8000;
上下文:	server


语法:	location [ = | ~ | ~* | ^~ ] uri { ... }
        location @name { ... }
默认值:	—
上下文:	server, location

语法:	log_not_found on | off;
默认值:	log_not_found on;
上下文:	http, server, location
开启或者关闭在error_log中记录文件不存在的错误。


语法:	log_subrequest on | off;
默认值:	log_subrequest off;
上下文:	http, server, location
开启或者关闭在access_log中记录子请求的访问日志。


语法:	max_ranges number;
默认值:	—
上下文:	http, server, location
如果请求中含有字节范围的请求头，这条指令可以限制此范围允许的最大值。如果请求头的值超过此限制，将按请求未携带此请求头的情况处理。 默认nginx对此不做限制。设置为0将使nginx完全不支持HTTP字节范围特性。


语法:	merge_slashes on | off;
默认值:	merge_slashes on;
上下文:	http, server
开启或者关闭将请求URI中相邻两个或更多斜线合并成一个的功能。


语法:	msie_padding on | off;
默认值:	msie_padding on;
上下文:	http, server, location
在响应状态码大于等于400时，在响应正文中添加一段注释，使响应正文达到512字节。 本指令可以为MSIE客户端开启或关闭这个功能。

语法:	msie_refresh on | off;
默认值:	msie_refresh off;
上下文:	http, server, location
为MSIE客户端开启或者关闭用页面刷新取代页面重定向的功能。

open_file_cache          max=1000 inactive=20s;
open_file_cache_valid    30s;
open_file_cache_min_uses 2;
open_file_cache_errors   on;

语法:	port_in_redirect on | off;
默认值:	port_in_redirect on;
上下文:	http, server, location
开启或关闭nginx发起重定向时指定端口。


语法:	postpone_output size;
默认值:	postpone_output 1460;
上下文:	http, server, location
如果可能，到客户端的数据将被推迟发送，直到nginx需要发送的数据至少有size字节。 设置为0将关闭推迟发送的功能。

语法:	read_ahead size;
默认值:	read_ahead 0;
上下文:	http, server, location
设置内核参数，控制文件预读的数量。

语法:	recursive_error_pages on | off;
默认值:	recursive_error_pages off;
上下文:	http, server, location
允许或禁止error_page指令进行多次重定向。 允许的话，重定向次数也有限制。


语法:	reset_timedout_connection on | off;
默认值:	reset_timedout_connection off;
上下文:	http, server, location
开启或关闭重置超时连接的功能。


语法:	resolver address ... [valid=time];
默认值:	—
上下文:	http, server, location
配置将后端服务器的名字解析成ip地址的名字服务器，比如：
resolver 127.0.0.1 [::1]:5353 valid=30s;

语法:	resolver_timeout time;
默认值:	resolver_timeout 30s;
上下文:	http, server, location
为名字解析设置超时

语法:	root path;
默认值:	root html;
上下文:	http, server, location, if in location
为请求设置根目录


语法:	satisfy all | any;
默认值:	
satisfy all;
上下文:	http, server, location
nginx进行访问限制的有ngx_http_access_module模块和 ngx_http_auth_basic_module模块。 本指令设置成all时，表示只有当两个模块的所有限制条件(写入配置的)都授权访问时，允许请求访问； 设置成any时，表示如果当任意模块的任意限制条件授权访问时，允许请求访问。


语法:	send_lowat size;
默认值:	send_lowat 0;
上下文:	http, server, location
如果设置成非0值，nginx将尝试最小化向客户端发送数据的次数。


语法:	send_timeout time;
默认值:	send_timeout 60s;
上下文:	http, server, location
设置向客户端传输响应的超时。超时仅指两次相邻写操作之间的时间间隔，而非整个响应的传输时间。


语法:	sendfile on | off;
默认值:	
sendfile off;
上下文:	http, server, location, if in location
开启或关闭使用sendfile()调用。

语法:	sendfile_max_chunk size;
默认值:	
sendfile_max_chunk 0;
上下文:	http, server, location
设置为非0值时，可以限制在一次sendfile()调用时传输的数据量。 如果不进行限制，一个快速的连接可能会霸占整个worker进程的所有资源。

语法:	server { ... }
默认值:	—
上下文:	http
表示开始设置虚拟主机的配置。

语法:	server_name_in_redirect on | off;
默认值:	
server_name_in_redirect off;
上下文:	http, server, location
开启或关闭nginx将server_name指令指定的首要虚拟主机名用于发起的重定向的功能。



    Collection 接口，不唯一，无序
        List 接口，有序，不唯一
        Set 接口，无序唯一
        SortedSet 有序 + 唯一

    Map
    Map 接口存储一组键值对象，提供key（键）到value（值）的映射。
        Map.Entry 描述在一个Map中的一个元素（键/值对）。
        SortedMap 使 Key 保持在升序排列。
        

    <servlet>
        <servlet-name>HelloServlet</servlet-name>
        <servlet-class>com.example.javaweb.HelloServlet</servlet-class>
    </servlet>

    <servlet-mapping>
        <servlet-name>HelloServlet</servlet-name>
        <url-pattern>/hello-servlet</url-pattern>
    </servlet-mapping>
    
#!/usr/bin/java --source 14


属性名	类名	属性描述
name	String	指定servlet的name属性，等价于<servlet-name>,若没有指定，则默认是类的全限定名
value	String[]	等价于urlPatterns，两者不能共存
urlPatterns	String[]	指定一组servlet的url的匹配模式，等价于<url-pattern>
loadOnStartup	int	指定servlet的加载顺序，等价于<load-on-startup>
initParams	WebinitParams[]	指定一组初始化参数，等价于<init-params>
asyncSupported	boolean	申明servlet是否支持异步操作模式，等价于<async-supported>
displayName	String	servlet的显示名，等价于<display-name>
description	String	servlet的描述信息，等价于<description>


consul agent -server -bootstrap-expect 3 -data-dir /tmp/consul -node=s1 -bind=172.22.147.212 -ui-dir ./consul_ui/ -rejoin -config-dir=/etc/consul/ -client 0.0.0.0

consul agent -dev
consul members  -detailed

curl localhost:8500/v1/catalog/nodes

dig @127.0.0.1 -p 8600 Armons-MacBook-Air.node.consul

sudo mkdir /etc/consul.d

echo '{"service": {"name": "web", "tags": ["rails"], "port": 80}}' > /etc/consul.d/web.json


consul agent -dev -config-dir=/etc/consul.d

dig @127.0.0.1 -p 8600 web.service.consul
dig @127.0.0.1 -p 8600 web.service.consul SRV


curl http://localhost:8500/v1/catalog/service/web

curl 'http://localhost:8500/v1/health/service/web?passing'

cat <<EOF | sudo tee /etc/consul.d/socat.json
{
  "service": {
    "name": "socat",
    "port": 8181,
    "connect": { "sidecar_service": {} }
  }
}
EOF


cat <<EOF | sudo tee /etc/consul.d/web.json
{
  "service": {
    "name": "web",
    "port": 8080,
    "connect": {
      "sidecar_service": {
        "proxy": {
          "upstreams": [{
             "destination_name": "socat",
             "local_bind_port": 9191
          }]
        }
      }
    }
  }
}
EOF


consul connect proxy -sidecar-for socat
consul reload
consul agent -server -bootstrap-expect=1 -data-dir=/tmp/consul -node=agent-one -bind=172.20.20.10 -enable-script-checks=true -config-dir=/etc/consul.d

run --network local --name node1,node2,node3 -dit -v /d/bin:/usr/local/bin ubuntu

/node4: 172.18.0.13
/node2: 172.18.0.11
/node1: 172.18.0.10
/node3: 172.18.0.12

consul agent -server -bootstrap-expect=1  -data-dir=/tmp/consul -node=agent-one -bind=172.18.0.10  -enable-script-checks=true -config-dir=/etc/consul.d

consul agent -data-dir=/tmp/consul -node=agent-two  -bind=172.18.0.11 -enable-script-checks=true -config-dir=/etc/consul.d


consul join 172.18.0.11


echo '{
"check": {
    "name": "ping",
    "args": ["ping", "-c1", "baidu.com"], "interval": "30s"}
}' >/etc/consul.d/ping.json


echo '{
    "service": {
        "name": "web",
        "tags": ["rails"], 
        "port": 80,
  "check": {"args": ["curl", "localhost"], "interval": "10s"}}
}' >/etc/consul.d/web.json


sudo useradd --system --home /etc/consul.d --shell /bin/false consul


一、什么是CPU亲和
是一种把CPU核心和Nginx工作进程绑定方式，把每个worker进程固定在一个cpu上执行，减少切换cpu的cache miss，获得更好的性能。

sendfile 零拷贝,直接通过内核空间,把文件传递给 socket,响应给用户

request     -请求行、请求头部、请求数据
response    -状态行、消息报头、响应正文

给网卡添加多个ip
ip a add 172.17.0.40/16 dev eth0





管理员身份打开 Powershell
运行Get-ExecutionPolicy 如果返回Restricted，则运行 Set-ExecutionPolicy AllSigned
Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))
choco install gsudo

nginx 变量
HTTP请求变量- arg_PARAMETER、http_HEADER、sent_http_HEADER
内置变量- Nginx内置的
自定义变量–自己定义





!includedir /etc/mysql/conf.d/
!includedir /etc/mysql/mysql.conf.d/


<beans>

    <bean id="bookService" class="BookService">
        <property name="dataSource" ref="dataSource" />
    </bean>

</beans>

@Component
@Autowired
@ComponentScan


@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE) // @Scope("prototype")

@Order(2)

@Autowired(required = false)

@Bean //Spring对标记为@Bean的方法只调用一次，因此返回的Bean仍然是单例

 @PostConstruct
 @PreDestroy 


@Bean("name")指定别名，也可以用@Bean+@Qualifier("name")指定别名

 @Profile("!test")
 @Profile({ "test", "master" }) // 同时满足test和master

 @Conditional(OnSmtpEnvCondition.class)
 @ConditionalOnProperty(name="app.smtp", havingValue="true")
 @ConditionalOnClass(name = "javax.mail.Transport")
 
@ConditionalOnProperty(name = "app.storage", havingValue = "file", matchIfMissing = true)


联机事务处理（OLTP）也称为面向交易的处理系统，其基本特征是原始数据可以立即传送到计算中心进行处理，并在很短的时间内给出处理结果。
联机分析处理（OLAP）是指通过多维的方式对数据进行分析、查询和报表，可以同数据挖掘工具、统计分析工具配合使用，增强决策分析功能。
关系型数据库，是建立在关系模型基础上的数据库，其借助于集合代数等数学概念和方法来处理数据库中的数据。主流的oracle、DB2、MS SQL Server和mysql都属于这类传统数据库。

Mycat是一个强大的数据库中间件，不仅仅可以用作读写分离、以及分表分库、容灾备份，而且可以用于多租户应用开发、云平台基础设施、让你的架构具备很强的适应性和灵活性，借助于即将发布的Mycat智能优化模块，系统的数据访问瓶颈和热点一目了然，根据这些统计分析数据，你可以自动或手工调整后端存储，将不同的表映射到不同存储引擎上，而整个应用的代码一行也不用改变。

./mycat console   { console | start | stop | restart | status | dump }


eval "return redis.call('set', KEYS[2], ARGV[2])" 3 k1 k2 k3 v1 v2 v3

eval "redis.call('set', KEYS[2], ARGV[2]); redis.pcall('set', KEYS[3], ARGV[3]);" 3 k1 k2 k3 v1 v2 v3
script load "return redis.call('set', KEYS[1], ARGV[1])"
script exists 55b22c0d0cedf3866879ce7c854970626dcef0c3
script flush
script kill
evalsha 55b22c0d0cedf3866879ce7c854970626dcef0c3 2 ke1 ke2 v1 v2
redis-cli --ldb --eval loop.lua ke1 k2 , v1 v2
h
